{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32dec2ce-a94b-47c8-af08-5b10df7fb480",
   "metadata": {},
   "source": [
    "### 1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "##### Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "##### You need to find following details:\n",
    "1. Rank\n",
    "2. Name\n",
    "3. Artist\n",
    "4. Upload date\n",
    "5. Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31afce38-dca8-4018-92e0-75b6865cdb02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1aab52be-3d37-471e-9059-fd6edf8046ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting the webpage https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# # getting the link\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9967f744-c122-42ee-a889-1525f0944ba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating Empty List\n",
    "Rank=[]\n",
    "Name=[]\n",
    "Artist=[]\n",
    "Upload_date=[]\n",
    "Views=[]\n",
    "\n",
    "# Scraping Rank data\n",
    "Rank_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[1]')))\n",
    "for i in Rank_data:\n",
    "    Rank.append(i.text[:-1])\n",
    "\n",
    "# Scraping Name Data\n",
    "Name_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[2]')))\n",
    "for i in Name_data:\n",
    "    Name.append(i.text.split('\"')[1])\n",
    "    \n",
    "# Scraping Artist Data\n",
    "Artist_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[3]')))\n",
    "for i in Artist_data:\n",
    "    Artist.append(i.text)\n",
    "    \n",
    "# Scraping Upload Date Data\n",
    "Upload_date_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[5]')))\n",
    "for i in Upload_date_data:\n",
    "    Upload_date.append(i.text)\n",
    "    \n",
    "# Scraping Views Data\n",
    "\n",
    "Views_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"][1]/tbody/tr/td[4]')))\n",
    "for i in Views_data:\n",
    "    Views.append(i.text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c18fa95-8dee-4feb-86a4-aad80a90676a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(Name),len(Artist),len(Upload_date),len(Views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cfee5211-3b3d-43d2-818c-b8e5d3f7400f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views(in Billion)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>12.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Bath Song</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Phonics Song with Two Words</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Learning Colors – Colorful Eggs on a Farm</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Masha and the Bear – Recipe for Disaster</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                 Video Name  \\\n",
       "0     1                           Baby Shark Dance   \n",
       "1     2                                  Despacito   \n",
       "2     3                       Johny Johny Yes Papa   \n",
       "3     4                                  Bath Song   \n",
       "4     5                               Shape of You   \n",
       "5     6                              See You Again   \n",
       "6     7                Phonics Song with Two Words   \n",
       "7     8                          Wheels on the Bus   \n",
       "8     9                                Uptown Funk   \n",
       "9    10  Learning Colors – Colorful Eggs on a Farm   \n",
       "10   11                              Gangnam Style   \n",
       "11   12   Masha and the Bear – Recipe for Disaster   \n",
       "12   13                             Dame Tu Cosita   \n",
       "13   14                                     Axel F   \n",
       "14   15                                      Sugar   \n",
       "15   16                                       Roar   \n",
       "16   17                             Counting Stars   \n",
       "17   18                                      Sorry   \n",
       "18   19                        Baa Baa Black Sheep   \n",
       "19   20                          Thinking Out Loud   \n",
       "20   21           Waka Waka (This Time for Africa)   \n",
       "21   22                                 Dark Horse   \n",
       "22   23                                      Faded   \n",
       "23   24                                    Perfect   \n",
       "24   25                             Lakdi Ki Kathi   \n",
       "25   26                                 Let Her Go   \n",
       "26   27                             Girls Like You   \n",
       "27   28          Humpty the train on a fruits ride   \n",
       "28   29                                    Lean On   \n",
       "29   30                                   Bailando   \n",
       "\n",
       "                                           Artist        Upload Date  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                      Luis Fonsi   January 12, 2017   \n",
       "2                                     LooLoo Kids    October 8, 2016   \n",
       "3                      Cocomelon – Nursery Rhymes        May 2, 2018   \n",
       "4                                      Ed Sheeran   January 30, 2017   \n",
       "5                                     Wiz Khalifa      April 6, 2015   \n",
       "6                                       ChuChu TV      March 6, 2014   \n",
       "7                      Cocomelon – Nursery Rhymes       May 24, 2018   \n",
       "8                                     Mark Ronson  November 19, 2014   \n",
       "9                                     Miroshka TV  February 27, 2018   \n",
       "10                                            Psy      July 15, 2012   \n",
       "11                                     Get Movies   January 31, 2012   \n",
       "12                                      El Chombo      April 5, 2018   \n",
       "13                                     Crazy Frog      June 16, 2009   \n",
       "14                                       Maroon 5   January 14, 2015   \n",
       "15                                     Katy Perry  September 5, 2013   \n",
       "16                                    OneRepublic       May 31, 2013   \n",
       "17                                  Justin Bieber   October 22, 2015   \n",
       "18                     Cocomelon – Nursery Rhymes      June 25, 2018   \n",
       "19                                     Ed Sheeran    October 7, 2014   \n",
       "20                                        Shakira       June 4, 2010   \n",
       "21                                     Katy Perry  February 20, 2014   \n",
       "22                                    Alan Walker   December 3, 2015   \n",
       "23                                     Ed Sheeran   November 9, 2017   \n",
       "24                                   Jingle Toons      June 14, 2018   \n",
       "25                                      Passenger      July 25, 2012   \n",
       "26                                       Maroon 5       May 31, 2018   \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "28                                    Major Lazer     March 22, 2015   \n",
       "29                               Enrique Iglesias     April 11, 2014   \n",
       "\n",
       "   Views(in Billion)  \n",
       "0              12.73  \n",
       "1               8.14  \n",
       "2               6.69  \n",
       "3               6.15  \n",
       "4               5.97  \n",
       "5               5.86  \n",
       "6               5.26  \n",
       "7               5.14  \n",
       "8               4.89  \n",
       "9               4.87  \n",
       "10              4.77  \n",
       "11              4.55  \n",
       "12              4.32  \n",
       "13              3.87  \n",
       "14              3.86  \n",
       "15              3.78  \n",
       "16              3.77  \n",
       "17              3.65  \n",
       "18              3.61  \n",
       "19              3.58  \n",
       "20              3.56  \n",
       "21              3.50  \n",
       "22              3.44  \n",
       "23              3.42  \n",
       "24              3.42  \n",
       "25              3.42  \n",
       "26              3.40  \n",
       "27              3.38  \n",
       "28              3.37  \n",
       "29              3.37  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Dataframe\n",
    "df1=pd.DataFrame({'Rank':Rank,'Video Name':Name,\"Artist\":Artist,'Upload Date':Upload_date,'Views(in Billion)':Views})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07cd2f43-9d16-49c0-9290-79a5fe809811",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf015f8-bdda-4ea3-ac60-ebba2eef9d77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "22b9f57d-5b09-4772-9a07-cb34c9299605",
   "metadata": {},
   "source": [
    "### 2. Scrape the details team India’s international fixtures from bcci.tv. \n",
    "##### Url = https://www.bcci.tv/.\n",
    "##### You need to find following details:\n",
    "1. Match title (I.e. 1stODI)\n",
    "2. Series\n",
    "3. Place\n",
    "4. Date\n",
    "5. Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35423a82-b641-408d-9ae2-6fc8158b92af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00acf46d-3864-49de-9785-91ff1d0f2e95",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting the webpage https://www.bcci.tv/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# # getting the link\n",
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5a48e0e-9a38-461a-b13c-98d31c406357",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clicking International Button\n",
    "int_btn = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'//*[@id=\"navigation\"]/ul[1]/li[2]/a')))\n",
    "int_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f44fe43a-61a2-4d8d-9da7-80a51edbf449",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating Empty Lists\n",
    "Match_title = []\n",
    "Series = []\n",
    "Place = []\n",
    "Date = []\n",
    "Time= []\n",
    "\n",
    "#Scraping Title Data\n",
    "Series_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//h5[@class=\"match-tournament-name ng-binding\"]')))\n",
    "for i in Series_data:\n",
    "    Series.append(i.text)\n",
    "\n",
    "#Scraping series and place Data\n",
    "Match_title_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"match-place ng-scope\"]')))\n",
    "for i in Match_title_data:\n",
    "    Match_title.append(i.text.split('-')[0])\n",
    "    Place.append(i.text.split('-')[1])\n",
    "\n",
    "#Scraping Date Data\n",
    "Date_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"match-dates ng-binding\"]')))\n",
    "for i in Date_data:\n",
    "    Date.append(i.text)\n",
    "    \n",
    "#Scraping Time Data\n",
    "Time_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"match-time no-margin ng-binding\"]')))\n",
    "for i in Time_data:\n",
    "    Time.append(i.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4b847188-a924-42bd-900e-0f7412fd298e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1 1 1\n"
     ]
    }
   ],
   "source": [
    "print(len(Match_title),len(Series),len(Place),len(Date),len(Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "613f353d-7991-487a-a8ad-71218a13fc67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Final</td>\n",
       "      <td>ICC WORLD TEST CHAMPIONSHIP FINAL 2023</td>\n",
       "      <td>Kennington Oval, London</td>\n",
       "      <td>7 JUN 2023</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match title                                  Series  \\\n",
       "0      Final   ICC WORLD TEST CHAMPIONSHIP FINAL 2023   \n",
       "\n",
       "                      Place        Date         Time  \n",
       "0   Kennington Oval, London  7 JUN 2023  3:30 PM IST  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame\n",
    "df2=pd.DataFrame({'Match title':Match_title,'Series':Series,\"Place\":Place,'Date':Date,'Time':Time})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f1ea307-0219-49cc-8d92-b3f7cb228837",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "839959b5-4c45-449d-98a6-480749d5b5c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "102fc209-6417-4649-a074-128669f16e32",
   "metadata": {},
   "source": [
    "### 3. Scrape the details of State-wise GDP of India from statisticstime.com. \n",
    "##### Url = http://statisticstimes.com/\n",
    "##### You have to find following details:\n",
    "1. Rank\n",
    "2. State\n",
    "3. GSDP(18-19)- at current prices\n",
    "4. GSDP(19-20)- at current prices\n",
    "5. Share(18-19)\n",
    "6. GDP($ billion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e48ac29-ec0b-4420-b703-9aabe4c991f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cc81309-6688-4ade-9b0f-936872e9593f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting the webpage http://statisticstimes.com/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# # getting the link\n",
    "driver.get('http://statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52634f54-0e3d-4c8c-a555-08f8b2435b0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Going to economy of india\n",
    "ecn_btn = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'/html/body/div[2]/div[1]/div[2]/div[2]/div/a[3]')))\n",
    "driver.get(ecn_btn.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc6ca153-0be3-4e91-a9b2-314c485c9f9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting state gdp of india page\n",
    "gdp_btn = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a')))\n",
    "driver.get(gdp_btn.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2d7c609-0517-4fbc-b753-ae19ea8251aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating Empty Lists\n",
    "Rank =[]\n",
    "State = []\n",
    "Gsdp_18_19=[]\n",
    "Share_18_19=[]\n",
    "Gsdp_19_20=[]\n",
    "Gdp=[]\n",
    "\n",
    "# Scraping Rank data\n",
    "Rank_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[1]')))\n",
    "for i in Rank_data:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "# Scraping State data\n",
    "State_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[2]')))\n",
    "for i in State_data:\n",
    "    State.append(i.text)\n",
    "\n",
    "# Scraping Gsdp(18-19) data\n",
    "Gsdp_18_19_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[4]')))\n",
    "for i in Gsdp_18_19_data:\n",
    "    Gsdp_18_19.append(i.text)\n",
    "\n",
    "# Scraping Gsdp(19-20) data\n",
    "Gsdp_19_20_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[3]')))\n",
    "for i in Gsdp_19_20_data:\n",
    "    Gsdp_19_20.append(i.text)\n",
    "\n",
    "# Scraping share(18-19) data\n",
    "Share_18_19_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[5]')))\n",
    "for i in Share_18_19_data:\n",
    "    Share_18_19.append(i.text)\n",
    "\n",
    "# Scraping Gdp data\n",
    "Gdp_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@id=\"table_id\"]/tbody/tr/td[6]')))\n",
    "for i in Gdp_data:\n",
    "    Gdp.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30933a70-01a5-481b-b13a-5cb7d2475531",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 33 33 33 33 33\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(State),len(Gsdp_19_20),len(Gsdp_18_19),len(Share_18_19),len(Gdp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb4a59c5-5226-4720-bbb1-8bafc4a08e5d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>Gsdp(19-20)</th>\n",
       "      <th>Gsdp(18-19)</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP (In $Billions)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>942,586</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>972,782</td>\n",
       "      <td>862,957</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>969,604</td>\n",
       "      <td>861,031</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>906,672</td>\n",
       "      <td>809,592</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>781,653</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>856,112</td>\n",
       "      <td>774,870</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>831,610</td>\n",
       "      <td>734,163</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>611,804</td>\n",
       "      <td>530,363</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>574,760</td>\n",
       "      <td>526,376</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>521,275</td>\n",
       "      <td>487,805</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>-</td>\n",
       "      <td>315,881</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>329,180</td>\n",
       "      <td>304,063</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>328,598</td>\n",
       "      <td>297,204</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>-</td>\n",
       "      <td>245,895</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>-</td>\n",
       "      <td>155,956</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>165,472</td>\n",
       "      <td>153,845</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>80,449</td>\n",
       "      <td>73,170</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>55,984</td>\n",
       "      <td>49,845</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>42,114</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>38,253</td>\n",
       "      <td>34,433</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>36,572</td>\n",
       "      <td>33,481</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>32,496</td>\n",
       "      <td>28,723</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>31,790</td>\n",
       "      <td>27,870</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>27,283</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>24,603</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>26,503</td>\n",
       "      <td>22,287</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State Gsdp(19-20) Gsdp(18-19) Share(18-19)  \\\n",
       "0     1                Maharashtra           -   2,632,792       13.94%   \n",
       "1     2                 Tamil Nadu   1,845,853   1,630,208        8.63%   \n",
       "2     3              Uttar Pradesh   1,687,818   1,584,764        8.39%   \n",
       "3     4                    Gujarat           -   1,502,899        7.96%   \n",
       "4     5                  Karnataka   1,631,977   1,493,127        7.91%   \n",
       "5     6                West Bengal   1,253,832   1,089,898        5.77%   \n",
       "6     7                  Rajasthan   1,020,989     942,586        4.99%   \n",
       "7     8             Andhra Pradesh     972,782     862,957        4.57%   \n",
       "8     9                  Telangana     969,604     861,031        4.56%   \n",
       "9    10             Madhya Pradesh     906,672     809,592        4.29%   \n",
       "10   11                     Kerala           -     781,653        4.14%   \n",
       "11   12                      Delhi     856,112     774,870        4.10%   \n",
       "12   13                    Haryana     831,610     734,163        3.89%   \n",
       "13   14                      Bihar     611,804     530,363        2.81%   \n",
       "14   15                     Punjab     574,760     526,376        2.79%   \n",
       "15   16                     Odisha     521,275     487,805        2.58%   \n",
       "16   17                      Assam           -     315,881        1.67%   \n",
       "17   18               Chhattisgarh     329,180     304,063        1.61%   \n",
       "18   19                  Jharkhand     328,598     297,204        1.57%   \n",
       "19   20                Uttarakhand           -     245,895        1.30%   \n",
       "20   21            Jammu & Kashmir           -     155,956        0.83%   \n",
       "21   22           Himachal Pradesh     165,472     153,845        0.81%   \n",
       "22   23                        Goa      80,449      73,170        0.39%   \n",
       "23   24                    Tripura      55,984      49,845        0.26%   \n",
       "24   25                 Chandigarh           -      42,114        0.22%   \n",
       "25   26                 Puducherry      38,253      34,433        0.18%   \n",
       "26   27                  Meghalaya      36,572      33,481        0.18%   \n",
       "27   28                     Sikkim      32,496      28,723        0.15%   \n",
       "28   29                    Manipur      31,790      27,870        0.15%   \n",
       "29   30                   Nagaland           -      27,283        0.14%   \n",
       "30   31          Arunachal Pradesh           -      24,603        0.13%   \n",
       "31   32                    Mizoram      26,503      22,287        0.12%   \n",
       "32   33  Andaman & Nicobar Islands           -           -            -   \n",
       "\n",
       "   GDP (In $Billions)  \n",
       "0             399.921  \n",
       "1             247.629  \n",
       "2             240.726  \n",
       "3             228.290  \n",
       "4             226.806  \n",
       "5             165.556  \n",
       "6             143.179  \n",
       "7             131.083  \n",
       "8             130.791  \n",
       "9             122.977  \n",
       "10            118.733  \n",
       "11            117.703  \n",
       "12            111.519  \n",
       "13             80.562  \n",
       "14             79.957  \n",
       "15             74.098  \n",
       "16             47.982  \n",
       "17             46.187  \n",
       "18             45.145  \n",
       "19             37.351  \n",
       "20             23.690  \n",
       "21             23.369  \n",
       "22             11.115  \n",
       "23              7.571  \n",
       "24              6.397  \n",
       "25              5.230  \n",
       "26              5.086  \n",
       "27              4.363  \n",
       "28              4.233  \n",
       "29              4.144  \n",
       "30              3.737  \n",
       "31              3.385  \n",
       "32                  -  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame\n",
    "df3 = pd.DataFrame({'Rank':Rank,'State':State,'Gsdp(19-20)':Gsdp_19_20,'Gsdp(18-19)':Gsdp_18_19,'Share(18-19)':Share_18_19,'GDP (In $Billions)':Gdp})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fa35073-6509-44b4-9fea-caad334641a3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d136b489-be31-4259-9984-e9adf1e5de3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "28d32a4d-2bba-4502-87a0-2e49b8360d20",
   "metadata": {},
   "source": [
    "### 4. Scrape the details of trending repositories on Github.com. \n",
    "##### Url = https://github.com/\n",
    "##### You have to find the following details:\n",
    "1. Repository title\n",
    "2. Repository description\n",
    "3. Contributors count\n",
    "4. Language used\n",
    "\n",
    "\n",
    "##### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00e5eb52-2328-4cec-bd72-0aceabb8ad03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "16a8b9fa-9179-4cb6-9b3b-5fc34b4b8c03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting the webpage https://github.com/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# # getting the link\n",
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d530afab-8a4d-4fad-b203-b6fe96fe6d57",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clicking open source tab\n",
    "op_src_btn = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/button')))\n",
    "op_src_btn.click()\n",
    "# Clicking Trending btn\n",
    "tr_btn = WebDriverWait(driver,10).until(EC.presence_of_element_located((By.XPATH,'/html/body/div[1]/div[1]/header/div/div[2]/div/nav/ul/li[3]/div/div[3]/ul/li[2]/a')))\n",
    "tr_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f9f8497c-cf26-46ff-bb36-f4d323f69b46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Creating Empty Lists\n",
    "title=[]\n",
    "description=[]\n",
    "Contributors_count=[]\n",
    "Language_used=[]\n",
    "url = []\n",
    "\n",
    "# Scraping Name Data\n",
    "title_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//h2[@class=\"h3 lh-condensed\"]/a')))\n",
    "\n",
    "for i in title_data:\n",
    "    title.append(i.text)\n",
    "    url.append(i.get_attribute('href'))\n",
    "\n",
    "# Scraping Description Data\n",
    "description_data = WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')))\n",
    "for i in description_data:\n",
    "    description.append(i.text)\n",
    "\n",
    "for j in range(len(url)):\n",
    "        \n",
    "    driver.get(url[j])\n",
    "    Contributors_count_data=WebDriverWait(driver,60).until(EC.presence_of_all_elements_located((By.XPATH,'//h2[@class=\"h4 mb-3\"]')))\n",
    "    for i in Contributors_count_data:\n",
    "        if i.text.split(' ')[0] == 'Contributors':\n",
    "            Contributors_count.append(i.text.split(' ')[1])\n",
    "    Language_used_data=WebDriverWait(driver,10).until(EC.presence_of_all_elements_located((By.XPATH,'//ul[@class=\"list-style-none\"]')))\n",
    "    for l in range(len(Language_used_data)-1,-1,-1):\n",
    "        if Language_used_data[l].text != \"\":\n",
    "            data = []\n",
    "            for k in range(0,len(Language_used_data[l].text.split('\\n')),2):\n",
    "                data.append(Language_used_data[l].text.split('\\n')[k])\n",
    "            Language_used.append(','.join(data))\n",
    "            break\n",
    "    if len(Contributors_count) < j+1:\n",
    "        Contributors_count.append('1')\n",
    "    if len(Language_used) < j+1:\n",
    "        Language_used.append('-')\n",
    "\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ce88099-56a8-42bf-b6b9-f3de4f4462d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 25 25 25\n"
     ]
    }
   ],
   "source": [
    "print(len(description),len(title),len(Language_used),len(Contributors_count),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "24c9c91e-d263-4673-8368-a62c71eed390",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "105b0bd6-fe31-4d7d-9c87-491842cf76d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Language used</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pengxiao-song / LaWGPT</td>\n",
       "      <td>🎉 Repo for LaWGPT, Chinese-Llama tuned with Ch...</td>\n",
       "      <td>Python,Shell</td>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/pengxiao-song/LaWGPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w-okada / voice-changer</td>\n",
       "      <td>リアルタイムボイスチェンジャー Realtime Voice Changer</td>\n",
       "      <td>TypeScript,Python,Jupyter Notebook,CSS,Shell,J...</td>\n",
       "      <td>7</td>\n",
       "      <td>https://github.com/w-okada/voice-changer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaiboWang / EasySpider</td>\n",
       "      <td>A visual no-code/code-free web crawler/spider一...</td>\n",
       "      <td>JavaScript,HTML,Python,Vue,CSS,TypeScript,Other</td>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/NaiboWang/EasySpider</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JiauZhang / DragGAN</td>\n",
       "      <td>Implementation of DragGAN: Interactive Point-b...</td>\n",
       "      <td>Python</td>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/JiauZhang/DragGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>XingangPan / DragGAN</td>\n",
       "      <td>Code for DragGAN (SIGGRAPH 2023)</td>\n",
       "      <td>-</td>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/XingangPan/DragGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UFund-Me / Qbot</td>\n",
       "      <td>[🔥updating ...] 自动量化交易机器人 Qbot is an AI-orient...</td>\n",
       "      <td>Jupyter Notebook,HTML,Python,Go,Vue,TypeScript...</td>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/UFund-Me/Qbot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adams549659584 / go-proxy-bingai</td>\n",
       "      <td>自行搭建暂时失效，等后续更新。主站先紧急修复了，需要一键重置下，看看能不能撑住了。</td>\n",
       "      <td>HTML,Go,JavaScript,Vue,TypeScript,CSS</td>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/adams549659584/go-proxy-bingai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SevaSk / ecoute</td>\n",
       "      <td>Ecoute is a live transcription tool that provi...</td>\n",
       "      <td>Python</td>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/SevaSk/ecoute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>FlowiseAI / Flowise</td>\n",
       "      <td>Drag &amp; drop UI to build your customized LLM fl...</td>\n",
       "      <td>JavaScript,TypeScript,CSS,SCSS,HTML,Dockerfile</td>\n",
       "      <td>7</td>\n",
       "      <td>https://github.com/FlowiseAI/Flowise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>facebookresearch / fairseq</td>\n",
       "      <td>Facebook AI Research Sequence-to-Sequence Tool...</td>\n",
       "      <td>Python,Other</td>\n",
       "      <td>302</td>\n",
       "      <td>https://github.com/facebookresearch/fairseq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>google / comprehensive-rust</td>\n",
       "      <td>This is the Rust course used by the Android te...</td>\n",
       "      <td>Rust,Assembly,Handlebars,JavaScript,Shell,C,Other</td>\n",
       "      <td>105</td>\n",
       "      <td>https://github.com/google/comprehensive-rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>kyrolabs / awesome-langchain</td>\n",
       "      <td>😎 Awesome list of tools and projects with the ...</td>\n",
       "      <td>-</td>\n",
       "      <td>14</td>\n",
       "      <td>https://github.com/kyrolabs/awesome-langchain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Zeqiang-Lai / DragGAN</td>\n",
       "      <td>Unofficial implementation of \"Drag Your GAN: I...</td>\n",
       "      <td>Python,Cuda,C++,Jupyter Notebook</td>\n",
       "      <td>1</td>\n",
       "      <td>https://github.com/Zeqiang-Lai/DragGAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>iryna-kondr / scikit-llm</td>\n",
       "      <td>Seamlessly integrate powerful language models ...</td>\n",
       "      <td>Python</td>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/iryna-kondr/scikit-llm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Blazity / next-enterprise</td>\n",
       "      <td>💼 An enterprise-grade Next.js boilerplate for ...</td>\n",
       "      <td>TypeScript,JavaScript,CSS</td>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/Blazity/next-enterprise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>imartinez / privateGPT</td>\n",
       "      <td>Interact privately with your documents using t...</td>\n",
       "      <td>TypeScript,JavaScript,CSS</td>\n",
       "      <td>3</td>\n",
       "      <td>https://github.com/imartinez/privateGPT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>ricklamers / gpt-code-ui</td>\n",
       "      <td>An open source implementation of OpenAI's Chat...</td>\n",
       "      <td>Python,TypeScript,CSS,Makefile,Shell,JavaScrip...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://github.com/ricklamers/gpt-code-ui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pedroslopez / whatsapp-web.js</td>\n",
       "      <td>A WhatsApp client library for NodeJS that conn...</td>\n",
       "      <td>JavaScript,Shell</td>\n",
       "      <td>91</td>\n",
       "      <td>https://github.com/pedroslopez/whatsapp-web.js</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Innocentsax / ALX-RESOURCES_FROM_BEGINNER_TO_A...</td>\n",
       "      <td>These REPO contains all ALX resources, with Ad...</td>\n",
       "      <td>-</td>\n",
       "      <td>5</td>\n",
       "      <td>https://github.com/Innocentsax/ALX-RESOURCES_F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>shadcn / ui</td>\n",
       "      <td>Beautifully designed components built with Rad...</td>\n",
       "      <td>TypeScript,JavaScript,CSS,Shell</td>\n",
       "      <td>61</td>\n",
       "      <td>https://github.com/shadcn/ui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>ClemensElflein / OpenMower</td>\n",
       "      <td>Let's upgrade cheap off-the-shelf robotic mowe...</td>\n",
       "      <td>C,C++,Other</td>\n",
       "      <td>6</td>\n",
       "      <td>https://github.com/ClemensElflein/OpenMower</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>hwchase17 / langchain</td>\n",
       "      <td>⚡ Building applications with LLMs through comp...</td>\n",
       "      <td>Python,Jupyter Notebook,Other</td>\n",
       "      <td>782</td>\n",
       "      <td>https://github.com/hwchase17/langchain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>arthurspk / guiadevbrasil</td>\n",
       "      <td>Um guia extenso de informações com um vasto co...</td>\n",
       "      <td>-</td>\n",
       "      <td>60</td>\n",
       "      <td>https://github.com/arthurspk/guiadevbrasil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>dair-ai / Prompt-Engineering-Guide</td>\n",
       "      <td>🐙 Guides, papers, lecture, notebooks and resou...</td>\n",
       "      <td>Jupyter Notebook,TypeScript,Other</td>\n",
       "      <td>78</td>\n",
       "      <td>https://github.com/dair-ai/Prompt-Engineering-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>anse-app / anse</td>\n",
       "      <td>Supercharged experience for ChatGPT, DALL-E an...</td>\n",
       "      <td>TypeScript,CSS,JavaScript,Astro,Dockerfile</td>\n",
       "      <td>8</td>\n",
       "      <td>https://github.com/anse-app/anse</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "0                              pengxiao-song / LaWGPT   \n",
       "1                             w-okada / voice-changer   \n",
       "2                              NaiboWang / EasySpider   \n",
       "3                                 JiauZhang / DragGAN   \n",
       "4                                XingangPan / DragGAN   \n",
       "5                                     UFund-Me / Qbot   \n",
       "6                    adams549659584 / go-proxy-bingai   \n",
       "7                                     SevaSk / ecoute   \n",
       "8                                 FlowiseAI / Flowise   \n",
       "9                          facebookresearch / fairseq   \n",
       "10                        google / comprehensive-rust   \n",
       "11                       kyrolabs / awesome-langchain   \n",
       "12                              Zeqiang-Lai / DragGAN   \n",
       "13                           iryna-kondr / scikit-llm   \n",
       "14                          Blazity / next-enterprise   \n",
       "15                             imartinez / privateGPT   \n",
       "16                           ricklamers / gpt-code-ui   \n",
       "17                      pedroslopez / whatsapp-web.js   \n",
       "18  Innocentsax / ALX-RESOURCES_FROM_BEGINNER_TO_A...   \n",
       "19                                        shadcn / ui   \n",
       "20                         ClemensElflein / OpenMower   \n",
       "21                              hwchase17 / langchain   \n",
       "22                          arthurspk / guiadevbrasil   \n",
       "23                 dair-ai / Prompt-Engineering-Guide   \n",
       "24                                    anse-app / anse   \n",
       "\n",
       "                                          Description  \\\n",
       "0   🎉 Repo for LaWGPT, Chinese-Llama tuned with Ch...   \n",
       "1              リアルタイムボイスチェンジャー Realtime Voice Changer   \n",
       "2   A visual no-code/code-free web crawler/spider一...   \n",
       "3   Implementation of DragGAN: Interactive Point-b...   \n",
       "4                    Code for DragGAN (SIGGRAPH 2023)   \n",
       "5   [🔥updating ...] 自动量化交易机器人 Qbot is an AI-orient...   \n",
       "6           自行搭建暂时失效，等后续更新。主站先紧急修复了，需要一键重置下，看看能不能撑住了。   \n",
       "7   Ecoute is a live transcription tool that provi...   \n",
       "8   Drag & drop UI to build your customized LLM fl...   \n",
       "9   Facebook AI Research Sequence-to-Sequence Tool...   \n",
       "10  This is the Rust course used by the Android te...   \n",
       "11  😎 Awesome list of tools and projects with the ...   \n",
       "12  Unofficial implementation of \"Drag Your GAN: I...   \n",
       "13  Seamlessly integrate powerful language models ...   \n",
       "14  💼 An enterprise-grade Next.js boilerplate for ...   \n",
       "15  Interact privately with your documents using t...   \n",
       "16  An open source implementation of OpenAI's Chat...   \n",
       "17  A WhatsApp client library for NodeJS that conn...   \n",
       "18  These REPO contains all ALX resources, with Ad...   \n",
       "19  Beautifully designed components built with Rad...   \n",
       "20  Let's upgrade cheap off-the-shelf robotic mowe...   \n",
       "21  ⚡ Building applications with LLMs through comp...   \n",
       "22  Um guia extenso de informações com um vasto co...   \n",
       "23  🐙 Guides, papers, lecture, notebooks and resou...   \n",
       "24  Supercharged experience for ChatGPT, DALL-E an...   \n",
       "\n",
       "                                        Language used Contributors count  \\\n",
       "0                                        Python,Shell                  2   \n",
       "1   TypeScript,Python,Jupyter Notebook,CSS,Shell,J...                  7   \n",
       "2     JavaScript,HTML,Python,Vue,CSS,TypeScript,Other                  3   \n",
       "3                                              Python                  1   \n",
       "4                                                   -                  1   \n",
       "5   Jupyter Notebook,HTML,Python,Go,Vue,TypeScript...                  1   \n",
       "6               HTML,Go,JavaScript,Vue,TypeScript,CSS                  1   \n",
       "7                                              Python                  1   \n",
       "8      JavaScript,TypeScript,CSS,SCSS,HTML,Dockerfile                  7   \n",
       "9                                        Python,Other                302   \n",
       "10  Rust,Assembly,Handlebars,JavaScript,Shell,C,Other                105   \n",
       "11                                                  -                 14   \n",
       "12                   Python,Cuda,C++,Jupyter Notebook                  1   \n",
       "13                                             Python                  2   \n",
       "14                          TypeScript,JavaScript,CSS                  3   \n",
       "15                          TypeScript,JavaScript,CSS                  3   \n",
       "16  Python,TypeScript,CSS,Makefile,Shell,JavaScrip...                  2   \n",
       "17                                   JavaScript,Shell                 91   \n",
       "18                                                  -                  5   \n",
       "19                    TypeScript,JavaScript,CSS,Shell                 61   \n",
       "20                                        C,C++,Other                  6   \n",
       "21                      Python,Jupyter Notebook,Other                782   \n",
       "22                                                  -                 60   \n",
       "23                  Jupyter Notebook,TypeScript,Other                 78   \n",
       "24         TypeScript,CSS,JavaScript,Astro,Dockerfile                  8   \n",
       "\n",
       "                                                  URL  \n",
       "0             https://github.com/pengxiao-song/LaWGPT  \n",
       "1            https://github.com/w-okada/voice-changer  \n",
       "2             https://github.com/NaiboWang/EasySpider  \n",
       "3                https://github.com/JiauZhang/DragGAN  \n",
       "4               https://github.com/XingangPan/DragGAN  \n",
       "5                    https://github.com/UFund-Me/Qbot  \n",
       "6   https://github.com/adams549659584/go-proxy-bingai  \n",
       "7                    https://github.com/SevaSk/ecoute  \n",
       "8                https://github.com/FlowiseAI/Flowise  \n",
       "9         https://github.com/facebookresearch/fairseq  \n",
       "10       https://github.com/google/comprehensive-rust  \n",
       "11      https://github.com/kyrolabs/awesome-langchain  \n",
       "12             https://github.com/Zeqiang-Lai/DragGAN  \n",
       "13          https://github.com/iryna-kondr/scikit-llm  \n",
       "14         https://github.com/Blazity/next-enterprise  \n",
       "15            https://github.com/imartinez/privateGPT  \n",
       "16          https://github.com/ricklamers/gpt-code-ui  \n",
       "17     https://github.com/pedroslopez/whatsapp-web.js  \n",
       "18  https://github.com/Innocentsax/ALX-RESOURCES_F...  \n",
       "19                       https://github.com/shadcn/ui  \n",
       "20        https://github.com/ClemensElflein/OpenMower  \n",
       "21             https://github.com/hwchase17/langchain  \n",
       "22         https://github.com/arthurspk/guiadevbrasil  \n",
       "23  https://github.com/dair-ai/Prompt-Engineering-...  \n",
       "24                   https://github.com/anse-app/anse  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame\n",
    "df4 = pd.DataFrame({'Title':title,'Description':description,'Language used':Language_used,'Contributors count':Contributors_count,'URL':url})\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aac1dfa-0687-4efb-b276-1062aeee8fef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "406eaf12-baff-4d7a-872d-f10216cf57f6",
   "metadata": {},
   "source": [
    "### 5. Scrape the details of top 100 songs on billiboard.com. \n",
    "##### Url = https://www.billboard.com/\n",
    "##### You have to find the following details:\n",
    "1. Song name\n",
    "2. Artist name\n",
    "3. Last week rank\n",
    "4. Peak rank\n",
    "5. Weeks on board\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abfa0e8e-9d43-41c3-9dd7-ed92c978a701",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "854654dd-c0a6-416f-a89c-3be973cdb0e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting the webpage https://www.billboard.com/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# # getting the link\n",
    "driver.get('https://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f9ae62b4-20b4-4b0b-9278-456b065688c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clicking charts button\n",
    "charts_btn = WebDriverWait(driver,30).until(EC.presence_of_element_located((By.XPATH,'/html/body/div[3]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a')))\n",
    "charts_btn.click()\n",
    "\n",
    "#clicking hot 100 button\n",
    "h_btn = WebDriverWait(driver,30).until(EC.presence_of_element_located((By.XPATH,'/html/body/div[3]/main/div[2]/div[1]/div[1]/div/div/div[3]')))\n",
    "driver.execute_script(\"window.scrollBy(0,700)\")\n",
    "time.sleep(1)\n",
    "h_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f33b18fc-75b5-4b8e-9bc4-6c9e1d557566",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating Empty List\n",
    "Song_name =[]\n",
    "Artist_name=[]\n",
    "Last_week_rank=[]\n",
    "Peak_rank=[]\n",
    "Weeks_on_board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af9f5b27-dd91-4cce-8d7e-f67c48ad210f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scraping Data\n",
    "data = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//ul[@class=\"lrv-a-unstyle-list lrv-u-flex lrv-u-height-100p lrv-u-flex-direction-column@mobile-max\"]')))\n",
    "for i in data:\n",
    "    Song_name.append(i.text.split('\\n')[0])\n",
    "    Artist_name.append(i.text.split('\\n')[1])\n",
    "    Last_week_rank.append(i.text.split('\\n')[2])\n",
    "    Peak_rank.append(i.text.split('\\n')[3])\n",
    "    Weeks_on_board.append(i.text.split('\\n')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0f4e6b19-8414-4432-9979-98263e1ee308",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Song_name),len(Artist_name),len(Last_week_rank),len(Peak_rank),len(Weeks_on_board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f812369d-e5ac-4f34-8bbd-cb8ecd76987d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>Lil Durk Featuring J. Cole</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ella Baila Sola</td>\n",
       "      <td>Eslabon Armado X Peso Pluma</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Forever</td>\n",
       "      <td>Lil Baby Featuring Fridayy</td>\n",
       "      <td>87</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Private Landing</td>\n",
       "      <td>Don Toliver Featuring Justin Bieber &amp; Future</td>\n",
       "      <td>100</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>I Heard</td>\n",
       "      <td>YoungBoy Never Broke Again</td>\n",
       "      <td>-</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Sunrise</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Happy</td>\n",
       "      <td>NF</td>\n",
       "      <td>95</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Song Name                                   Artist Name  \\\n",
       "0        Last Night                                 Morgan Wallen   \n",
       "1       All My Life                    Lil Durk Featuring J. Cole   \n",
       "2           Flowers                                   Miley Cyrus   \n",
       "3         Kill Bill                                           SZA   \n",
       "4   Ella Baila Sola                   Eslabon Armado X Peso Pluma   \n",
       "..              ...                                           ...   \n",
       "95          Forever                    Lil Baby Featuring Fridayy   \n",
       "96  Private Landing  Don Toliver Featuring Justin Bieber & Future   \n",
       "97          I Heard                    YoungBoy Never Broke Again   \n",
       "98          Sunrise                                 Morgan Wallen   \n",
       "99            Happy                                            NF   \n",
       "\n",
       "   Last week rank Peak Rank Weeks on board  \n",
       "0               1         1             16  \n",
       "1               -         2              1  \n",
       "2               3         1             18  \n",
       "3               2         1             23  \n",
       "4               4         4              9  \n",
       "..            ...       ...            ...  \n",
       "95             87         8             19  \n",
       "96            100        72              6  \n",
       "97              -        98              1  \n",
       "98             89        30             11  \n",
       "99             95        54              6  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame\n",
    "df5 = pd.DataFrame({'Song Name':Song_name,'Artist Name':Artist_name,'Last week rank':Last_week_rank,'Peak Rank':Peak_rank,'Weeks on board':Weeks_on_board})\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "db6c4be9-15d9-4cbd-8698-16eaf8d985b8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48207d9c-b392-40bd-a78a-3a6e82896aaa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c14262a1-afcf-4844-8f8c-2ca09b7ed215",
   "metadata": {},
   "source": [
    "### 6. Scrape the details of Highest sellingnovels.\n",
    "##### Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "##### You have to find the following details:\n",
    "1. Book name\n",
    "2. Author name\n",
    "3. Volumes sold\n",
    "4. Publisher\n",
    "5. Genre\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eeffd4a1-2702-4643-8346-5d7875b62b92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c723761b-d14b-4d2f-81c4-d496c2f4a4a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting the webpage https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# # getting the link\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a1e977d-0faf-4e77-ba49-731f511008b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating Empty Lists\n",
    "Book_name=[]\n",
    "Author_name=[]\n",
    "Volumes_sold=[]\n",
    "Publisher=[]\n",
    "Genre=[]\n",
    "\n",
    "\n",
    "#Scraping Name Data\n",
    "Book_name_data = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[2]')))\n",
    "for i in Book_name_data:\n",
    "    Book_name.append(i.text)\n",
    "\n",
    "#Scraping Author Name Data\n",
    "Author_name_data = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[3]')))\n",
    "for i in Author_name_data:\n",
    "    Author_name.append(i.text)\n",
    "    \n",
    "#Scraping Volumes sold Data\n",
    "Volumes_sold_data = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[4]')))\n",
    "for i in Volumes_sold_data:\n",
    "    Volumes_sold.append(i.text)\n",
    "    \n",
    "#Scraping Publisher Data\n",
    "Publisher_data = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[5]')))\n",
    "for i in Publisher_data:\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "#Scraping Genre Data\n",
    "Genre_data = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@class=\"in-article sortable\"]/tbody/tr/td[6]')))\n",
    "for i in Genre_data:\n",
    "    Genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ec6c7ea0-970a-4998-89a3-573ccf44d087",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Book_name),len(Author_name),len(Volumes_sold),len(Publisher),len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9e443dce-b24d-4e0b-912a-a64aa3fa56a8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame\n",
    "df6 = pd.DataFrame({'Book Name':Book_name,'Author name':Author_name,'Volumes Sold':Volumes_sold,'Publisher':Publisher,'Genre':Genre})\n",
    "\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d53bc59c-cb05-4531-8187-34d0084046a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a495b06a-09da-4984-a910-eef6f481d9a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d627849e-9e3f-466d-837a-90a101490e5d",
   "metadata": {},
   "source": [
    "### 7. Scrape the details most watched tv series of all time from imdb.com. \n",
    "##### Url = https://www.imdb.com/list/ls095964455/\n",
    "##### You have to find the following details:\n",
    "1. Name\n",
    "2. Year span\n",
    "3. Genre\n",
    "4. Run time\n",
    "5. Ratings\n",
    "6. Votes\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "31c19f2a-7aa7-40a1-b7b7-1244efbc3549",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6546fdc-126c-41e5-91b0-70811e591aec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting the webpage  https://www.imdb.com/list/ls095964455/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# # getting the link\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d751f4c6-49c6-46fe-a435-d43735077788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating Empty Lists\n",
    "Name = []\n",
    "Year_span = []\n",
    "Genre = []\n",
    "Run_time = []\n",
    "Ratings=[]\n",
    "Votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9428641c-6d09-47cc-81f6-6f61e42f36c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scraping Name Data\n",
    "Name_data = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//h3[@class=\"lister-item-header\"]/a')))\n",
    "for i in Name_data:\n",
    "    Name.append(i.text)\n",
    "\n",
    "\n",
    "# Scraping Year Span Data\n",
    "Year_span_data = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]')))\n",
    "for i in Year_span_data:\n",
    "    Year_span.append(i.text)\n",
    "\n",
    "#Scraping Genre Data\n",
    "Genre_data = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"lister-item-content\"]//p[1]/span[5]')))\n",
    "for i in Genre_data:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "#Scraping Run Time Data\n",
    "Run_time_data = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"lister-item-content\"]//p[1]/span[3]')))\n",
    "for i in Run_time_data:\n",
    "    Run_time.append(i.text)\n",
    "\n",
    "# Scraping Ratings Data\n",
    "Ratings_data= WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"lister-item-content\"]/div[1]/div[1]/span[2]')))\n",
    "for i in Ratings_data:\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "# Scraping Votes Data\n",
    "Votes_data = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"lister-item-content\"]/p[4]/span[2]')))\n",
    "for i in Votes_data:\n",
    "    Votes.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12fddb9a-3bfa-4e38-b0a0-c279aa1ecf25",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Year_span),len(Genre),len(Run_time),len(Ratings),len(Votes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcbe8e38-1b1c-4ba3-8d85-4fc41754c462",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,161,690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2022)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,241,978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,026,974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>302,106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>261,202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>51,656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>63,688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>207,604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>258,046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2022)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run time Ratings      Votes  \n",
       "0    57 min     9.2  2,161,690  \n",
       "1    51 min     8.7  1,241,978  \n",
       "2    44 min     8.1  1,026,974  \n",
       "3    60 min     7.5    302,106  \n",
       "4    43 min     7.6    261,202  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     51,656  \n",
       "96   50 min     7.8     63,688  \n",
       "97   42 min     8.1    207,604  \n",
       "98   45 min       7     43,193  \n",
       "99  572 min     8.6    258,046  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame\n",
    "df7 = pd.DataFrame({'Name':Name,'Year span':Year_span,'Genre':Genre,'Run time':Run_time,'Ratings':Ratings,'Votes':Votes})\n",
    "\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b2d505d2-7451-4baf-a14a-f910a0a11594",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fec465f-8509-4172-91e3-c4725ca9b854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2808bd6-60ab-4c56-b007-c3678996d145",
   "metadata": {},
   "source": [
    "### 8. Details of Datasets from UCI machine learning repositories. \n",
    "##### Url = https://archive.ics.uci.edu/\n",
    "##### You have to find the following details:\n",
    "1. Dataset name\n",
    "2. Data type\n",
    "3. Task\n",
    "4. Attribute type\n",
    "5. No of instances\n",
    "6. No of attribute\n",
    "7. Year\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bef17f05-742e-48b4-988d-05a0b5c62ddd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f42a7d3b-5c93-4eb2-8d70-816baf654e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting the webpage  https://archive.ics.uci.edu/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# # getting the link\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "005f8a03-7d10-420d-a643-c1a470a44dc1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Clicking view all Data sets\n",
    "View_btn=WebDriverWait(driver,30).until(EC.presence_of_element_located((By.XPATH,'/html/body/table[2]/tbody/tr/td/span/b/a')))\n",
    "View_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "482515b8-b342-4c3a-a2ce-d3b7668002d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating empty Lists\n",
    "Dataset_name = []\n",
    "Data_type = []\n",
    "Task = []\n",
    "Attribute_type = []\n",
    "No_of_instances = []\n",
    "No_of_attribute = []\n",
    "Year = []\n",
    "\n",
    "# Scraing data\n",
    "data =  WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//table[@border=\"1\"]//p[@class=\"normal\"]')))\n",
    "for i in range(0,len(data),7):\n",
    "    Dataset_name.append(data[i].text)\n",
    "\n",
    "for i in range(1,len(data),7):\n",
    "    Data_type.append(data[i].text)    \n",
    "    \n",
    "for i in range(2,len(data),7):\n",
    "    Task.append(data[i].text)\n",
    "    \n",
    "for i in range(3,len(data),7):\n",
    "    Attribute_type.append(data[i].text)\n",
    "    \n",
    "for i in range(4,len(data),7):\n",
    "    No_of_instances.append(data[i].text)\n",
    "    \n",
    "for i in range(5,len(data),7):\n",
    "    No_of_attribute.append(data[i].text)\n",
    "    \n",
    "for i in range(6,len(data),7):\n",
    "    Year.append(data[i].text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "df85f7ad-0679-4c22-8baf-b69a5300b71e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "622 622 622 622 622 622 622\n"
     ]
    }
   ],
   "source": [
    "print(len(Dataset_name),len(Data_type),len(Task),len(Attribute_type),len(No_of_instances),len(No_of_attribute),len(Year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c91f7168-9cb0-41fb-9272-af6c826034d0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of instances</th>\n",
       "      <th>No of attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset Name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data Type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute Type No of instances No of attribute   Year  \n",
       "0    Categorical, Integer, Real            4177               8   1995   \n",
       "1          Categorical, Integer           48842              14   1996   \n",
       "2    Categorical, Integer, Real             798              38          \n",
       "3                   Categorical           37711             294   1998   \n",
       "4    Categorical, Integer, Real             452             279   1998   \n",
       "..                           ...             ...             ...    ...  \n",
       "617               Integer, Real           75840             525   2020   \n",
       "618               Integer, Real             400              50   2020   \n",
       "619                                        1014               7   2020   \n",
       "620                        Real           10129              16   2021   \n",
       "621                        Real            4000               2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame\n",
    "df8 = pd.DataFrame({'Dataset Name':Dataset_name,'Data Type':Data_type,'Task':Task,'Attribute Type':Attribute_type,'No of instances':No_of_instances,'No of attribute':No_of_attribute,'Year':Year})\n",
    "\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41bc16e7-6c89-405e-9f64-70a4769a1c70",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e382c7f-c5cd-45bf-ac4f-68f66ae6c29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14214d7-7226-4e6b-882c-5045f52c9143",
   "metadata": {},
   "source": [
    "### 9. Scrape the details of Data science recruiters \n",
    "##### Url = https://www.naukri.com/hr-recruiters-consultants\n",
    "##### You have to find the following details: \n",
    "1. Name\n",
    "2. Designation\n",
    "3. Company \n",
    "4. Skills they hire for \n",
    "5. Location\n",
    "\n",
    "Note: - From naukri.com homepage click on the recruiters option and then on the search pane type Data science and \n",
    "click on search. All this should be done through code\n",
    "\n",
    "#### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e10d5151-5454-4dbf-a611-674a04480126",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "63dbe5a4-fd0f-43bc-a872-f549b0b039c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# getting the webpage  https://www.naukri.com/hr-recruiters-consultants\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# # getting the link\n",
    "driver.get('https://www.naukri.com/hr-recruiters-consultants')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d5803566-1482-4ac1-89b8-2921ac230072",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Entering Data science on search Bar\n",
    "Search_bar = WebDriverWait(driver,30).until(EC.presence_of_element_located((By.XPATH,'/html/body/div[2]/div[2]/div[1]/div[1]/form/div[1]/div/div[1]/div[1]/div[2]/input')))\n",
    "Search_bar.send_keys('Data science')\n",
    "Search_bar.send_keys(Keys.RETURN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6fc47b59-3a59-44a3-a39a-7e19d46ebe74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating Empty Lists\n",
    "Name = []\n",
    "Designation = []\n",
    "Company=[]\n",
    "Skills = []\n",
    "Location=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dbaf7c56-1cdb-467d-a8f3-87b65233003b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Scraping Name,Designation,Company & Location Data\n",
    "while True:\n",
    "    try:\n",
    "        Name_data = WebDriverWait(driver,5).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"vcard\"]')))\n",
    "    except:\n",
    "        break\n",
    "    for i in Name_data:\n",
    "        try:\n",
    "            Name.append(i.text.split('\\n')[0])\n",
    "        except:\n",
    "            Name.append('-')\n",
    "        try:\n",
    "            Designation.append(i.text.split('\\n')[1])\n",
    "        except:\n",
    "            Designation.append('-')\n",
    "        try:\n",
    "            Company.append(i.text.split('\\n')[2])\n",
    "        except:\n",
    "            Company.append('-')\n",
    "        try:\n",
    "            Location.append(i.text.split('\\n')[3])\n",
    "        except:\n",
    "            Location.append('-')\n",
    "\n",
    "\n",
    "\n",
    "    # Scraping Skills Data\n",
    "    Skills_data = WebDriverWait(driver,30).until(EC.presence_of_all_elements_located((By.XPATH,'//div[@class=\"hireSec highlightable\"]')))\n",
    "    for i in Skills_data:\n",
    "        Skills.append(i.text)\n",
    "\n",
    "    # Clicking Next Button\n",
    "\n",
    "    try:\n",
    "        Nxt_btn = WebDriverWait(driver,5).until(EC.presence_of_element_located((By.XPATH,'//button[contains(text(),\"Next\")]')))\n",
    "\n",
    "        Nxt_btn.click()\n",
    "\n",
    "    except:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ad43dddd-cf1f-4edf-a15c-2e4012378e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150 150 150 150 150\n"
     ]
    }
   ],
   "source": [
    "print(len(Designation),len(Company),len(Location),len(Skills),len(Name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c6de1b77-53c4-4691-a092-95db09048688",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Designation</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Skills</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aakash Harit</td>\n",
       "      <td>HR Manager</td>\n",
       "      <td>Data Science Network</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>Classic ASP Developer, Internet Marketing Prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>shravan Kumar Gaddam</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Shore Infotech India Pvt. Ltd</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>.Net, Java, Data Science, Linux Administration...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Company HR</td>\n",
       "      <td>MARSIAN Technologies LLP</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Data Science, Artificial Intelligence, Machine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anik Agrawal</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Enerlytics Software Solutions Pvt Ltd</td>\n",
       "      <td>Ahmedabad</td>\n",
       "      <td>Mean Stack, javascript, angularjs, mongodb, We...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>subhas patel</td>\n",
       "      <td>Founder CEO</td>\n",
       "      <td>LibraryXProject</td>\n",
       "      <td>UK - (london)</td>\n",
       "      <td>Hadoop, Spark, Digital Strategy, Data Architec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Sathya</td>\n",
       "      <td>Company Recruiter</td>\n",
       "      <td>Sathya Technologies</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Teaching, tableau, Power Bi, Data Analytics, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Sindhuja</td>\n",
       "      <td>Hr Associate</td>\n",
       "      <td>Cappius</td>\n",
       "      <td>Hyderabad / Secunderabad</td>\n",
       "      <td>Big Data Analytics, Full Mean Stack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Amit Nagar</td>\n",
       "      <td>Founder</td>\n",
       "      <td>CONNEXIONS</td>\n",
       "      <td>Bengaluru / Bangalore</td>\n",
       "      <td>fintech, Big Data, angularjs, sales, nosql, Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Kusum Gaur</td>\n",
       "      <td>Recruitment Associate</td>\n",
       "      <td>Microsoft Corporation</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Mobile Application Development, Atg Developer,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Mohammad Raashid</td>\n",
       "      <td>Recruitment Consultant</td>\n",
       "      <td>Freelancer</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Manufacturing Industry, construction, IT Industry</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name             Designation  \\\n",
       "0                Aakash Harit              HR Manager   \n",
       "1        shravan Kumar Gaddam       Company Recruiter   \n",
       "2    MARSIAN Technologies LLP              Company HR   \n",
       "3                Anik Agrawal       Company Recruiter   \n",
       "4                subhas patel             Founder CEO   \n",
       "..                        ...                     ...   \n",
       "145                    Sathya       Company Recruiter   \n",
       "146                  Sindhuja            Hr Associate   \n",
       "147                Amit Nagar                 Founder   \n",
       "148                Kusum Gaur   Recruitment Associate   \n",
       "149          Mohammad Raashid  Recruitment Consultant   \n",
       "\n",
       "                                   Company                  Location  \\\n",
       "0                     Data Science Network                     Delhi   \n",
       "1            Shore Infotech India Pvt. Ltd  Hyderabad / Secunderabad   \n",
       "2                 MARSIAN Technologies LLP                      Pune   \n",
       "3    Enerlytics Software Solutions Pvt Ltd                 Ahmedabad   \n",
       "4                          LibraryXProject             UK - (london)   \n",
       "..                                     ...                       ...   \n",
       "145                    Sathya Technologies  Hyderabad / Secunderabad   \n",
       "146                                Cappius  Hyderabad / Secunderabad   \n",
       "147                             CONNEXIONS     Bengaluru / Bangalore   \n",
       "148                  Microsoft Corporation                   Gurgaon   \n",
       "149                             Freelancer                    Mumbai   \n",
       "\n",
       "                                                Skills  \n",
       "0    Classic ASP Developer, Internet Marketing Prof...  \n",
       "1    .Net, Java, Data Science, Linux Administration...  \n",
       "2    Data Science, Artificial Intelligence, Machine...  \n",
       "3    Mean Stack, javascript, angularjs, mongodb, We...  \n",
       "4    Hadoop, Spark, Digital Strategy, Data Architec...  \n",
       "..                                                 ...  \n",
       "145  Teaching, tableau, Power Bi, Data Analytics, s...  \n",
       "146                Big Data Analytics, Full Mean Stack  \n",
       "147  fintech, Big Data, angularjs, sales, nosql, Co...  \n",
       "148  Mobile Application Development, Atg Developer,...  \n",
       "149  Manufacturing Industry, construction, IT Industry  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating Data Frame\n",
    "df9 = pd.DataFrame({'Name':Name,'Designation':Designation,'Company':Company,'Location':Location,'Skills':Skills})\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "caedd3b2-d37e-4027-abf8-e97d2cce2682",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
