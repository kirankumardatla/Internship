{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843669df-58c8-4c51-88db-3bfb6c0727b8",
   "metadata": {},
   "source": [
    "### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a69f3cae-fc82-4711-a21b-72a91c5d5427",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5725e56-e896-4f1b-982f-e002225da286",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1 : getting the webpage https://www.naukri.com/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# going to naukari.com\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65812c5d-6e56-45a8-bb26-c066598f41c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 2:Entering “Data Analyst” in “Skill, Designations, Companies” field and “Bangalore” in “enter the location” field.\n",
    "\n",
    "# Entering designation\n",
    "designation = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[1]/div/div/div/div[1]/div/input')\n",
    "designation.send_keys('Data Analyst')\n",
    "\n",
    "# Entering Location\n",
    "location = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6f8a3a5-4693-41a2-9d8c-d17b38316a43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 3 : clicking the search button. \n",
    "\n",
    "search_btn = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[6]')\n",
    "search_btn.click()\n",
    "# witing for page to load properly\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7f5fcb1-0612-4c11-9077-a08fe7e0e86b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 4: scraping the data for the first 10 jobs results\n",
    "\n",
    "#creating empty lists\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required  = []\n",
    "\n",
    "# Screaping job titles\n",
    "job_tit_data = driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in range(10):\n",
    "    job_title.append(job_tit_data[i].text)\n",
    "\n",
    "# Screaping job location\n",
    "job_loc_data = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in range(10):\n",
    "    job_location.append(job_loc_data[i].text)\n",
    "\n",
    "# Screaping company name\n",
    "company_name_data = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in range(10):\n",
    "    company_name.append(company_name_data[i].text)\n",
    "\n",
    "# Screaping experience required \n",
    "experience_required_data = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in range(10):\n",
    "    experience_required.append(experience_required_data[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "45995258-0548-4b76-a2ef-a907379cf6f7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df1c9bad-63bc-498b-9e63-8aab5778117d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst - FinTech</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Primo Hiring</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Analyst - IIT/BITS/Startups</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>AVE Promagne</td>\n",
       "      <td>1-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Banking Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, G...</td>\n",
       "      <td>Coforge</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Dpdzero</td>\n",
       "      <td>1-3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Juniper Networks</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Noida, Pune, ...</td>\n",
       "      <td>Infogain</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Portcast</td>\n",
       "      <td>2-6 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Job Title  \\\n",
       "0  Data Analyst - IIT/BITS/Startups   \n",
       "1            Data Analyst - FinTech   \n",
       "2            Data Analyst - FinTech   \n",
       "3            Data Analyst - FinTech   \n",
       "4  Data Analyst - IIT/BITS/Startups   \n",
       "5              Banking Data Analyst   \n",
       "6                      Data Analyst   \n",
       "7                      Data Analyst   \n",
       "8                      Data Analyst   \n",
       "9                      Data Analyst   \n",
       "\n",
       "                                        Job Location      Company Name  \\\n",
       "0                                Bangalore/Bengaluru      AVE Promagne   \n",
       "1  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...      Primo Hiring   \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...      Primo Hiring   \n",
       "3  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...      Primo Hiring   \n",
       "4                                Bangalore/Bengaluru      AVE Promagne   \n",
       "5  Bangalore/Bengaluru, Hyderabad/Secunderabad, G...           Coforge   \n",
       "6                                Bangalore/Bengaluru           Dpdzero   \n",
       "7                                Bangalore/Bengaluru  Juniper Networks   \n",
       "8  Temp. WFH - Bangalore/Bengaluru, Noida, Pune, ...          Infogain   \n",
       "9  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...          Portcast   \n",
       "\n",
       "  Experience Required  \n",
       "0             1-5 Yrs  \n",
       "1             1-2 Yrs  \n",
       "2             1-2 Yrs  \n",
       "3             1-2 Yrs  \n",
       "4             1-5 Yrs  \n",
       "5            5-10 Yrs  \n",
       "6             1-3 Yrs  \n",
       "7             5-9 Yrs  \n",
       "8             4-7 Yrs  \n",
       "9             2-6 Yrs  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 5 : creating a dataframe of the scraped data.\n",
    "df1 = pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name,'Experience Required':experience_required})\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d20658-834c-4119-8156-2d2fc32fd46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7fa87dd-8314-410d-ac45-e4e8565f21e0",
   "metadata": {},
   "source": [
    "### Q2:Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0741933f-87d6-42c8-a8f9-258191cff790",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d488830-115a-42f9-99ec-712cff60122a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1 : getting the webpage https://www.naukri.com/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# going to naukari.com\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ad87e93-a4c9-44f3-8215-3985927036d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 2:Entering “Data Scientist” in “Skill, Designations, Companies” field and “Bangalore” in “enter the location” field.\n",
    "\n",
    "# Entering designation\n",
    "designation = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[1]/div/div/div/div[1]/div/input')\n",
    "designation.send_keys('Data Scientist')\n",
    "\n",
    "# Entering Location\n",
    "location = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[5]/div/div/div/div[1]/div/input')\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "49d32bf1-c609-4eb8-a0ba-81e558f29fc8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 3 : clicking the search button. \n",
    "\n",
    "search_btn = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[6]')\n",
    "search_btn.click()\n",
    "# witing for page to load properly\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5df66617-15f9-4a45-a9d9-6ed494fd399b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 4: scraping the data for the first 10 jobs results\n",
    "\n",
    "#creating empty lists\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "\n",
    "# Screaping job titles\n",
    "job_tit_data = driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in range(10):\n",
    "    job_title.append(job_tit_data[i].text)\n",
    "\n",
    "# Screaping job location\n",
    "job_loc_data = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in range(10):\n",
    "    job_location.append(job_loc_data[i].text)\n",
    "\n",
    "# Screaping company name\n",
    "company_name_data = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in range(10):\n",
    "    company_name.append(company_name_data[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "28d3a79c-8e26-4111-8329-8c29e6feaab2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7b244f1-fc81-4d81-93ae-3aa53f7b8c0f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist_NLP</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Machine Learning (AI) Architect</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...</td>\n",
       "      <td>Persistent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Science Analyst - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Science Analyst Data Science</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Analytics Specialist - Artificial Intelligence...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Walmart</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist, Engineering at Google</td>\n",
       "      <td>Temp. WFH - Bangalore/Bengaluru, Hyderabad/Sec...</td>\n",
       "      <td>Blob Infotech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Opportunity | Data Scientist | Tavant India</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Kolkata, Hyderabad...</td>\n",
       "      <td>Tavant Technologies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sr. Data Scientist - Python / ML / DL</td>\n",
       "      <td>Bangalore/Bengaluru, Noida, Mumbai, Chandigarh...</td>\n",
       "      <td>AVE Promagne</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job Title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                                 Data Scientist_NLP   \n",
       "2                    Machine Learning (AI) Architect   \n",
       "3                Data Science Analyst - Data Science   \n",
       "4                  Data Science Analyst Data Science   \n",
       "5  Analytics Specialist - Artificial Intelligence...   \n",
       "6                              Senior Data Scientist   \n",
       "7              Data Scientist, Engineering at Google   \n",
       "8        Opportunity | Data Scientist | Tavant India   \n",
       "9              Sr. Data Scientist - Python / ML / DL   \n",
       "\n",
       "                                        Job Location         Company Name  \n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...            Accenture  \n",
       "1  Bangalore/Bengaluru, Mumbai, Pune, Chennai, Gu...    Fractal Analytics  \n",
       "2  Bangalore/Bengaluru, Kolkata, Mumbai, New Delh...           Persistent  \n",
       "3                                Bangalore/Bengaluru            Accenture  \n",
       "4                                Bangalore/Bengaluru            Accenture  \n",
       "5                                Bangalore/Bengaluru            Accenture  \n",
       "6                                Bangalore/Bengaluru              Walmart  \n",
       "7  Temp. WFH - Bangalore/Bengaluru, Hyderabad/Sec...        Blob Infotech  \n",
       "8  Bangalore/Bengaluru, Noida, Kolkata, Hyderabad...  Tavant Technologies  \n",
       "9  Bangalore/Bengaluru, Noida, Mumbai, Chandigarh...         AVE Promagne  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 5 : creating a dataframe of the scraped data.\n",
    "df2 = pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name})\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4f3fd0-deac-4baf-96ae-00cef9013b69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2a48088b-858c-4db5-b805-9f0edad23ad0",
   "metadata": {},
   "source": [
    "### Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "##### You have to use the location and salary filter.\n",
    "##### You have to scrape data for “Data Scientist” designation for first 10 job results. \n",
    "##### You have to scrape the job-title, job-location, company name, experience required.\n",
    "##### The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7be1920d-40b7-43a1-a85a-13b7532f90e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a93021bc-aca0-4824-a868-e184cca1f46c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1 : getting the webpage https://www.naukri.com/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# going to naukari.com\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c5762aa6-d1b8-41ac-86b0-3206cef84f8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 2:Entering “Data Scientist” in “Skill, Designations, Companies” field.\n",
    "# Entering designation\n",
    "designation = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[1]/div/div/div/div[1]/div/input')\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7fbccd6f-cd5f-453b-9743-30556e1d58fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 3 : clicking the search button. \n",
    "\n",
    "search_btn = driver.find_element(By.XPATH,'/html/body/div[1]/div[7]/div/div/div[6]')\n",
    "search_btn.click()\n",
    "# witing for page to load properly\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "73eab855-a7e6-4b65-b0eb-c9f43e6dd28e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 4 : Applying the location filter and salary filter by checking the respective boxes\n",
    "\n",
    "# Applying Delhi/NCR in location filter\n",
    "loc_filter = driver.find_element(By.XPATH,'//span[@title=\"Delhi / NCR\"]')\n",
    "loc_filter.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8fd7f483-3a09-4a0d-9667-151541759e1a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Applying “3-6” lakhs in salary filter\n",
    "salary_filter = driver.find_element(By.XPATH,'//span[@title=\"3-6 Lakhs\"]')\n",
    "salary_filter.click()\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8bf78e1d-7527-44a5-b150-e8242466d3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 4: scraping the data for the first 10 jobs results\n",
    "\n",
    "#creating empty lists\n",
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required  = []\n",
    "\n",
    "# Screaping job titles\n",
    "job_tit_data = driver.find_elements(By.XPATH,'//a[@class=\"title ellipsis\"]')\n",
    "for i in range(10):\n",
    "    job_title.append(job_tit_data[i].text)\n",
    "\n",
    "# Screaping job location\n",
    "job_loc_data = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft locWdth\"]')\n",
    "for i in range(10):\n",
    "    job_location.append(job_loc_data[i].text)\n",
    "\n",
    "# Screaping company name\n",
    "company_name_data = driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "for i in range(10):\n",
    "    company_name.append(company_name_data[i].text)\n",
    "\n",
    "# Screaping experience required \n",
    "experience_required_data = driver.find_elements(By.XPATH,'//span[@class=\"ellipsis fleft expwdth\"]')\n",
    "for i in range(10):\n",
    "    experience_required.append(experience_required_data[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c38d8b37-99ff-44f8-a41a-9cc670309746",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a8c6e381-dbcd-4ff4-a998-8da244576982",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Job Location</th>\n",
       "      <th>Company Name</th>\n",
       "      <th>Experience Required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>Blackbuck</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...</td>\n",
       "      <td>Analytos</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Junior Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, United States (USA), Bulgaria</td>\n",
       "      <td>Adidas</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist - II (Contract)</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Netomi</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Gujarat Fluorochemicals</td>\n",
       "      <td>1-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Research Scientist - Bioinformatics</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Biopeople India</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Scientist - I</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Netomi</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Machine Learning Engineer</td>\n",
       "      <td>Noida</td>\n",
       "      <td>Profit By Outsourcing</td>\n",
       "      <td>2-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Assistant Manager - Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram</td>\n",
       "      <td>Fidelity International</td>\n",
       "      <td>5-7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Job Title  \\\n",
       "0                Junior Data Scientist   \n",
       "1                       Data Scientist   \n",
       "2                       Data Scientist   \n",
       "3                Junior Data Scientist   \n",
       "4       Data Scientist - II (Contract)   \n",
       "5                       Data Scientist   \n",
       "6  Research Scientist - Bioinformatics   \n",
       "7                   Data Scientist - I   \n",
       "8            Machine Learning Engineer   \n",
       "9   Assistant Manager - Data Scientist   \n",
       "\n",
       "                                        Job Location             Company Name  \\\n",
       "0  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...                 Analytos   \n",
       "1              Gurgaon/Gurugram, Bangalore/Bengaluru                Blackbuck   \n",
       "2  Kolkata, Mumbai, New Delhi, Hyderabad/Secunder...                 Analytos   \n",
       "3    Gurgaon/Gurugram, United States (USA), Bulgaria                   Adidas   \n",
       "4                                   Gurgaon/Gurugram                   Netomi   \n",
       "5                                              Noida  Gujarat Fluorochemicals   \n",
       "6                                   Gurgaon/Gurugram          Biopeople India   \n",
       "7                                   Gurgaon/Gurugram                   Netomi   \n",
       "8                                              Noida    Profit By Outsourcing   \n",
       "9                                   Gurgaon/Gurugram   Fidelity International   \n",
       "\n",
       "  Experience Required  \n",
       "0             0-2 Yrs  \n",
       "1             3-7 Yrs  \n",
       "2             2-4 Yrs  \n",
       "3             1-6 Yrs  \n",
       "4             3-7 Yrs  \n",
       "5             1-2 Yrs  \n",
       "6             0-2 Yrs  \n",
       "7             3-6 Yrs  \n",
       "8             2-7 Yrs  \n",
       "9             5-7 Yrs  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 6 : creating a dataframe of the scraped data.\n",
    "df3 = pd.DataFrame({'Job Title':job_title,'Job Location':job_location,'Company Name':company_name,'Experience Required':experience_required})\n",
    "df3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229c6834-683c-4433-b9be-ba13894ac8a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b00bab8a-de3f-44a4-954f-170c291f9633",
   "metadata": {},
   "source": [
    "### Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Price\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e67f2fa-d4d5-4fea-ab92-9ef65fa8659d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5cb64875-e7c2-4b60-918f-a8083c162ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1 : getting the webpage https://www.flipkart.com/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# going to naukari.com\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1c10e944-31c1-48c4-bebc-03b1ddf1ff5f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# skipping the login page\n",
    "skip_login = driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "skip_login.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b243af39-94ce-4ff5-9c58-370bc1b17a46",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2:Enter “sunglasses” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "\n",
    "#Entering “sunglasses” in the search field\n",
    "search_field = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search_field.send_keys('sunglasses')\n",
    "\n",
    "#clicking the search icon\n",
    "search_icon = driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')\n",
    "search_icon.click()\n",
    "# witing for page to load properly\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "08f36c5f-ff11-435d-914f-dd864e0ac1ec",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 3: scraping the data form the first page\n",
    "\n",
    "#creating empty lists\n",
    "Brand = []\n",
    "ProductDescription = []\n",
    "Price = []\n",
    "\n",
    "# Screaping data\n",
    "product_data =  driver.find_elements(By.XPATH,'//div[@class=\"_2B099V\"]') \n",
    "for i in product_data:\n",
    "    Brand.append(i.text.split('\\n')[0])\n",
    "    ProductDescription.append(i.text.split('\\n')[1])\n",
    "    Price.append(i.text.split('\\n')[2].split('₹')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd30b78-a111-4fb2-870f-dd95e9f4dfd3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dd0f6004-aa5b-4e73-aafe-032663ddf615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(ProductDescription),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0c92235e-1be6-4848-9253-463a39884bd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4 : clicking next button\n",
    "next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "next_btn.click()\n",
    "# witing for page to load properly\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b2e48aa-19b7-4b11-aa79-778c9aaa7fb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 5 : scraping data from this page asusual\n",
    "product_data =  driver.find_elements(By.XPATH,'//div[@class=\"_2B099V\"]') \n",
    "for i in product_data:\n",
    "    Brand.append(i.text.split('\\n')[0])\n",
    "    ProductDescription.append(i.text.split('\\n')[1])\n",
    "    Price.append(i.text.split('\\n')[2].split('₹')[1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d3449f72-7fdb-4c0f-b2de-79f16ee2a657",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80 80 80\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(ProductDescription),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a3f82d9c-bc84-4751-af20-bac0a7bf0be7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# step 6 : Repeat this until you get data for 100sunglasses.\n",
    "while len(Brand) < 100:\n",
    "# clicking next button\n",
    "    next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_btn.click()\n",
    "    time.sleep(5)\n",
    "# scraping data from this page \n",
    "    product_data =  driver.find_elements(By.XPATH,'//div[@class=\"_2B099V\"]') \n",
    "    for i in product_data:\n",
    "        Brand.append(i.text.split('\\n')[0])\n",
    "        ProductDescription.append(i.text.split('\\n')[1])\n",
    "        Price.append(i.text.split('\\n')[2].split('₹')[1])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ec5882f2-e306-4f3a-b52a-89df57938887",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(ProductDescription),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9b68cda7-56f6-469c-a2e5-0a5b1c29fa05",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Oval Sunglasses (60)</td>\n",
       "      <td>598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NuVew</td>\n",
       "      <td>UV Protection Sports Sunglasses (69)</td>\n",
       "      <td>345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (53)</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Cat-eye, Retro Square, Oval, Rou...</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>UV Protection Clubmaster Sunglasses (54)</td>\n",
       "      <td>224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Oval, Aviator Sunglasses (60)</td>\n",
       "      <td>845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (Free Size)</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Fastrack</td>\n",
       "      <td>Gradient, UV Protection Wayfarer Sunglasses (F...</td>\n",
       "      <td>539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Shaah Collection</td>\n",
       "      <td>UV Protection, Polarized, Mirrored Rectangular...</td>\n",
       "      <td>185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>AISLIN</td>\n",
       "      <td>UV Protection Oval, Aviator Sunglasses (65)</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Brand                                Product Description Price\n",
       "0             AISLIN                 UV Protection Oval Sunglasses (60)   598\n",
       "1              NuVew               UV Protection Sports Sunglasses (69)   345\n",
       "2          Elligator             UV Protection Wayfarer Sunglasses (53)   149\n",
       "3          Elligator  UV Protection Cat-eye, Retro Square, Oval, Rou...   149\n",
       "4             PIRASO           UV Protection Clubmaster Sunglasses (54)   224\n",
       "..               ...                                                ...   ...\n",
       "95            AISLIN        UV Protection Oval, Aviator Sunglasses (60)   845\n",
       "96          Fastrack      UV Protection Wayfarer Sunglasses (Free Size)   579\n",
       "97          Fastrack  Gradient, UV Protection Wayfarer Sunglasses (F...   539\n",
       "98  Shaah Collection  UV Protection, Polarized, Mirrored Rectangular...   185\n",
       "99            AISLIN        UV Protection Oval, Aviator Sunglasses (65)   685\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 7 : Creating Data Frame\n",
    "df4 = pd.DataFrame({'Brand':Brand[:100],'Product Description':ProductDescription[:100],'Price':Price[:100]})\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8136a96e-05fa-4ce3-a1ce-891d2b6bb901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8df15197-b84e-4744-ba8a-cca59741e3c8",
   "metadata": {},
   "source": [
    "### Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: \n",
    "https://www.flipkart.com/apple-iphone-11-black-64-gb/product\u0002reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market\n",
    "place=FLIPKART\n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "568ca2b0-98a0-4a8e-9c5a-f69ff5b9dc6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8f8c606a-942b-4dfd-9c97-cc8f8c6b83a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1 : getting the required webpage \n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# going to naukari.com\n",
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market')\n",
    "# witing for page to load properly\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c0838ffc-92e3-4e30-a381-791536def4b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2 : Creating empty lists for web scraping\n",
    "Rating = []\n",
    "Review_summary = []\n",
    "Full_review = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff3bb16a-7054-4c5b-aed3-41711ee948c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3 : Scraping First Page\n",
    "data = driver.find_elements(By.XPATH,'//div[@class=\"col _2wzgFH K0kLPL\"]')\n",
    "for i in data:\n",
    "    Rating.append(i.text.split(\"\\n\")[0])\n",
    "    Review_summary.append(i.text.split(\"\\n\")[1])\n",
    "    Full_review.append('\\n'.join(i.text.split('\\n')[2:-4]))\n",
    "time.sleep(2)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c510e6fa-04e1-4688-a9ac-97cb5167fcf8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4 : Clicking next button\n",
    "next_btn = driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[2]')\n",
    "# displaying next btn and clicking it\n",
    "next_btn.location_once_scrolled_into_view\n",
    "next_btn.click()\n",
    "\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "407a21bf-e376-40e1-8b20-c4c14ab569d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 5 : Scraping Until we get 100 results\n",
    "while len(Rating) <100:\n",
    "    \n",
    "    data = driver.find_elements(By.XPATH,'//div[@class=\"col _2wzgFH K0kLPL\"]')\n",
    "    for i in data:\n",
    "        Rating.append(i.text.split(\"\\n\")[0])\n",
    "        Review_summary.append(i.text.split(\"\\n\")[1])\n",
    "        Full_review.append('\\n'.join(i.text.split('\\n')[2:-4]))\n",
    "        \n",
    "    if len(Rating)==len(Review_summary) and len(Rating)==len(Full_review):\n",
    "        #clicking next button\n",
    "        next_btn = driver.find_element(By.XPATH,'/html/body/div/div/div[3]/div/div/div[2]/div[13]/div/div/nav/a[12]')\n",
    "        next_btn.location_once_scrolled_into_view\n",
    "        next_btn.click()\n",
    "        # Waiting for page to load\n",
    "        time.sleep(3)\n",
    "    else:\n",
    "        raise Exception ('Sorry, values are Not Equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a3ec4918-245c-444d-a8d4-7279745b01cd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Rating),len(Review_summary),len(Full_review))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5ebc1fab-577e-476b-9e80-2147f244f975",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review summary</th>\n",
       "      <th>Full review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Simply awesome</td>\n",
       "      <td>Really satisfied with the Product I received.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Amazing phone with great cameras and better ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Great iPhone very snappy experience as apple k...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Value-for-money</td>\n",
       "      <td>I'm Really happy with the product\\nDelivery wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Highly recommended</td>\n",
       "      <td>It's my first time to use iOS phone and I am l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>4</td>\n",
       "      <td>Good quality product</td>\n",
       "      <td>I'm switching this phone to oppo reno 10x zoom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>Its good.. a little heavy on my pinky but its ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Simply Awesome\\n\\nI have upgraded from iPhone ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Damn this phone is a blast . Upgraded from and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Worth the money’ starting first from its perfo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating        Review summary  \\\n",
       "0       5        Simply awesome   \n",
       "1       5      Perfect product!   \n",
       "2       5   Best in the market!   \n",
       "3       4       Value-for-money   \n",
       "4       5    Highly recommended   \n",
       "..    ...                   ...   \n",
       "95      4  Good quality product   \n",
       "96      5             Wonderful   \n",
       "97      5              Terrific   \n",
       "98      5   Best in the market!   \n",
       "99      5      Perfect product!   \n",
       "\n",
       "                                          Full review  \n",
       "0   Really satisfied with the Product I received.....  \n",
       "1   Amazing phone with great cameras and better ba...  \n",
       "2   Great iPhone very snappy experience as apple k...  \n",
       "3   I'm Really happy with the product\\nDelivery wa...  \n",
       "4   It's my first time to use iOS phone and I am l...  \n",
       "..                                                ...  \n",
       "95  I'm switching this phone to oppo reno 10x zoom...  \n",
       "96  Its good.. a little heavy on my pinky but its ...  \n",
       "97  Simply Awesome\\n\\nI have upgraded from iPhone ...  \n",
       "98  Damn this phone is a blast . Upgraded from and...  \n",
       "99  Worth the money’ starting first from its perfo...  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df5 = pd.DataFrame({'Rating':Rating,'Review summary':Review_summary,'Full review':Full_review})\n",
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72084e1d-5a1b-47de-a38a-851a8c5ed6ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6fcbe55d-00b3-4f02-8111-8430498385e1",
   "metadata": {},
   "source": [
    "### Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the search field.\n",
    "### You have to scrape 3 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. ProductDescription\n",
    "3. Pric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "186f012f-bd2e-4491-9a03-175f4b7cba9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "730a2644-6c1d-4866-9e83-a384a3a9772e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1 : getting the webpage https://www.flipkart.com/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# going to naukari.com\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "04e66829-f39f-4159-b83b-6e65fd29d758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# skipping the login page\n",
    "skip_login = driver.find_element(By.XPATH,'/html/body/div[2]/div/div/button')\n",
    "skip_login.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fd710482-8d31-452f-b4b7-c7a2793d33c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2:Enter “sneakers” in the search field where “search for products, brands and more” is written and click the search icon\n",
    "\n",
    "#Entering “sneakers” in the search field\n",
    "search_field = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input')\n",
    "search_field.send_keys('sneakers')\n",
    "\n",
    "#clicking the search icon\n",
    "search_icon = driver.find_element(By.XPATH,'//button[@class=\"L0Z3Pu\"]')\n",
    "search_icon.click()\n",
    "# witing for page to load properly\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb84b5d6-46b2-4d61-a466-63b7141e3d92",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 3: scraping the data form the first page\n",
    "\n",
    "#creating empty lists\n",
    "Brand = []\n",
    "ProductDescription = []\n",
    "Price = []\n",
    "\n",
    "# Screaping data\n",
    "product_data =  driver.find_elements(By.XPATH,'//div[@class=\"_2B099V\"]') \n",
    "for i in product_data:\n",
    "    Brand.append(i.text.split('\\n')[0])\n",
    "    ProductDescription.append(i.text.split('\\n')[1])\n",
    "    Price.append(i.text.split('\\n')[2].split('₹')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cab9bd0f-6ac3-4a0c-abc5-551b026c1957",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 40 40\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(ProductDescription),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "468e0d84-e6f1-4641-af08-90ff6af547f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4 : clicking next button\n",
    "next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "next_btn.click()\n",
    "# witing for page to load properly\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "55fc456e-e74b-4130-950e-8a4d456534f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# step 5 : Repeat this until you get data for 100sunglasses.\n",
    "while len(Brand) < 100:\n",
    "\n",
    "# scraping data from this page \n",
    "    product_data =  driver.find_elements(By.XPATH,'//div[@class=\"_2B099V\"]') \n",
    "    for i in product_data:\n",
    "        Brand.append(i.text.split('\\n')[0])\n",
    "        ProductDescription.append(i.text.split('\\n')[1])\n",
    "        Price.append(i.text.split('\\n')[2].split('₹')[1]) \n",
    "# clicking next button\n",
    "    next_btn=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_btn.click()\n",
    "    time.sleep(5)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7105e0b9-e15e-4099-a0f3-6550ac44b696",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120 120 120\n"
     ]
    }
   ],
   "source": [
    "print(len(Brand),len(ProductDescription),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71c6fd65-167e-42ad-92da-300283ea70dd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Labbin</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Premium Casual Shoes Extra Lace Sneakers For W...</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Combo Pack Of 2 Casual Shoes Sneakers For Men</td>\n",
       "      <td>499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RINDAS</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Synthetic| Lightweight| Premiun| Comfort| Summ...</td>\n",
       "      <td>299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Casual Shoes Sneakers For Women</td>\n",
       "      <td>323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>ATOM</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>1,495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>RapidBox</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>HIGHLANDER</td>\n",
       "      <td>Sneakers For Men</td>\n",
       "      <td>497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Layasa</td>\n",
       "      <td>Casual Sneakers White Shoes For Girls And Snea...</td>\n",
       "      <td>449</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand                                Product Description  Price\n",
       "0       Labbin                                   Sneakers For Men    429\n",
       "1        BIRDE  Premium Casual Shoes Extra Lace Sneakers For W...    349\n",
       "2        BIRDE      Combo Pack Of 2 Casual Shoes Sneakers For Men    499\n",
       "3       RINDAS                                 Sneakers For Women    399\n",
       "4         aadi  Synthetic| Lightweight| Premiun| Comfort| Summ...    299\n",
       "..         ...                                                ...    ...\n",
       "95       BIRDE                    Casual Shoes Sneakers For Women    323\n",
       "96        ATOM                                   Sneakers For Men  1,495\n",
       "97    RapidBox                                   Sneakers For Men    579\n",
       "98  HIGHLANDER                                   Sneakers For Men    497\n",
       "99      Layasa  Casual Sneakers White Shoes For Girls And Snea...    449\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# STEP 7 : Creating Data Frame\n",
    "df6 = pd.DataFrame({'Brand':Brand[:100],'Product Description':ProductDescription[:100],'Price':Price[:100]})\n",
    "df6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fff52be-b1ba-4261-b705-f7b6e6b2b102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "47b6b8be-ef21-45ce-9a82-3901f499c9d2",
   "metadata": {},
   "source": [
    "### Q7: Go to webpage https://www.amazon.in/ Enter “Laptop” in the search field and then click the search icon. Then \n",
    "### set CPU Type filter to “Intel Core i7” as shown in the below image:\n",
    "### After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7f31f910-14ce-4131-823f-4db4b1306cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2eb746fa-3e68-4f15-be6b-ecdf922413fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1 : getting the webpage https://www.flipkart.com/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# going to naukari.com\n",
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "06cde7b1-726b-4065-9af0-4bbc98f603f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2:Entering “Laptop” in the search field and click the search icon\n",
    "\n",
    "#Entering “Laptop” in the search field\n",
    "search_field = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "search_field.send_keys('Laptop')\n",
    "\n",
    "#clicking the search icon\n",
    "search_icon = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[3]/div/span/input')\n",
    "search_icon.click()\n",
    "# witing for page to load properly\n",
    "time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "07b7e124-87d6-437f-90b2-61f2537ba069",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3 : Setting CPU type filter to “Intel Core i7”\n",
    "filter_icon = driver.find_element(By.XPATH,'/html/body/div[1]/div[2]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[6]/span[9]/li/span/a/span')\n",
    "filter_icon.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7b4a4a06-663f-4820-8a10-53c88995da8e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 3: scraping the data form the first page\n",
    "\n",
    "#creating empty lists\n",
    "Title = []\n",
    "Ratings = []\n",
    "Price = []\n",
    "\n",
    "# Screaping data \n",
    "product_data =  driver.find_elements(By.XPATH,'//div[@class=\"a-section a-spacing-small a-spacing-top-small\"]')\n",
    "# Scraping 10 products which contain ratings data\n",
    "p = 0\n",
    "\n",
    "for i in product_data:\n",
    "    if p < 10:\n",
    "        try:\n",
    "            Ratings.append(int(i.text.split('\\n')[1]))\n",
    "            Title.append(i.text.split('\\n')[0])\n",
    "            # gettring price text based on great summer sale text\n",
    "            if i.text.split('\\n')[2]=='Great Summer Sale':\n",
    "                \n",
    "                Price.append(i.text.split('\\n')[3].split(' ')[0])\n",
    "            else:\n",
    "                Price.append(i.text.split('\\n')[2].split(' ')[0])\n",
    "            p+=1\n",
    "        except:\n",
    "            # if error occurs means rating data is not int hence skip\n",
    "            continue\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9bf4b1db-601f-46ba-91cf-0b77fdd0d1e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Ratings),len(Price),len(Title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "975074fc-dc77-4fe9-ab0b-d165ed350615",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Price</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i3-1115G4 11t...</td>\n",
       "      <td>₹32,990</td>\n",
       "      <td>171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HP 15s, 11th Gen Intel Core i3 8GB RAM/1TB HDD...</td>\n",
       "      <td>₹38,490</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS Vivobook 14, Intel Core i3-1115G4 11th Ge...</td>\n",
       "      <td>₹34,990</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Lenovo IdeaPad 3 11th Gen Intel Core i3 15.6\" ...</td>\n",
       "      <td>₹36,490</td>\n",
       "      <td>493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dell Vostro 3420 Laptop,12th Gen Intel Core i3...</td>\n",
       "      <td>₹39,990</td>\n",
       "      <td>165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS VivoBook 15, Intel Core i3-1115G4 11th Ge...</td>\n",
       "      <td>₹35,990</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ASUS VivoBook 14, Intel Core i3-1115G4 11th Ge...</td>\n",
       "      <td>₹34,990</td>\n",
       "      <td>237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP 15s, 11th Gen Intel Core i3, 8GB RAM/512GB ...</td>\n",
       "      <td>₹40,950</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo IdeaPad Slim 3 Intel Core i3 11th Gen 1...</td>\n",
       "      <td>₹37,490</td>\n",
       "      <td>146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ASUS Vivobook 15, Intel Core i3-1220P 12th Gen...</td>\n",
       "      <td>₹40,990</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title    Price  Ratings\n",
       "0  Lenovo IdeaPad Slim 3 Intel Core i3-1115G4 11t...  ₹32,990      171\n",
       "1  HP 15s, 11th Gen Intel Core i3 8GB RAM/1TB HDD...  ₹38,490       63\n",
       "2  ASUS Vivobook 14, Intel Core i3-1115G4 11th Ge...  ₹34,990      237\n",
       "3  Lenovo IdeaPad 3 11th Gen Intel Core i3 15.6\" ...  ₹36,490      493\n",
       "4  Dell Vostro 3420 Laptop,12th Gen Intel Core i3...  ₹39,990      165\n",
       "5  ASUS VivoBook 15, Intel Core i3-1115G4 11th Ge...  ₹35,990       20\n",
       "6  ASUS VivoBook 14, Intel Core i3-1115G4 11th Ge...  ₹34,990      237\n",
       "7  HP 15s, 11th Gen Intel Core i3, 8GB RAM/512GB ...  ₹40,950      245\n",
       "8  Lenovo IdeaPad Slim 3 Intel Core i3 11th Gen 1...  ₹37,490      146\n",
       "9  ASUS Vivobook 15, Intel Core i3-1220P 12th Gen...  ₹40,990       30"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4 : Creating Data Frame\n",
    "df7 = pd.DataFrame({'Title':Title,'Price':Price,'Ratings':Ratings})\n",
    "df7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2ae848-3c4e-45bf-98e9-f55b8b4c2c88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d73fa62-b370-4907-a3e3-8c5d1dce4d77",
   "metadata": {},
   "source": [
    "### Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "### The above task will be done in following steps:\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on TopQuotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9896a69e-b864-4daf-9a3b-69ee58af6c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7fca9a43-3d9b-4821-bcc9-9f30faf41838",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1 : getting the webpage https://www.azquotes.com/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# going to naukari.com\n",
    "driver.get('https://www.azquotes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "710ff8ff-a76a-493d-a66d-0f0b7c93a10c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2 : Clicking on top quotes\n",
    "top_quotes_btn = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "top_quotes_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e0dfa692-a739-401d-9ec2-c6b358912b61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3 : Scraping 1st page\n",
    "\n",
    "#Creating Empty Lists\n",
    "Quote = []\n",
    "Author = []\n",
    "Type_of_Quote = []\n",
    "\n",
    "#scraping data\n",
    "data = driver.find_elements(By.XPATH,'//div[@class=\"wrap-block\"]')\n",
    "\n",
    "for i in data:\n",
    "    Quote.append(i.text.split('\\n')[0])\n",
    "    Author.append(i.text.split('\\n')[1])\n",
    "    Type_of_Quote.append(i.text.split('\\n')[2])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "57904f53-271a-4a61-82dc-1957c3d033af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Quote),len(Author),len(Type_of_Quote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4db68185-7ead-42f7-839b-e1d667b9ef1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4 : clicking next button\n",
    "next_btn = driver.find_element(By.XPATH,'//li[@class=\"next\"]')\n",
    "next_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e698ee1d-3c1c-4e40-a49b-b103bc784389",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 5 : repeating Process untill we get 1000 quotes\n",
    "\n",
    "while len(Quote) <1000:\n",
    "    #scraping data\n",
    "    data = driver.find_elements(By.XPATH,'//div[@class=\"wrap-block\"]')\n",
    "\n",
    "    for i in data:\n",
    "        Quote.append(i.text.split('\\n')[0])\n",
    "        Author.append(i.text.split('\\n')[1])\n",
    "        Type_of_Quote.append(i.text.split('\\n')[2])\n",
    "    #Skipping next when no of quotes = 1000    \n",
    "    if len(Quote) <1000:\n",
    "        #clicking next button\n",
    "        next_btn = driver.find_element(By.XPATH,'//li[@class=\"next\"]')\n",
    "        next_btn.click()\n",
    "        # waiting for page to load properly\n",
    "        time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e5be34f9-206d-47fc-bb56-278ae00ab4fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 1000 1000\n"
     ]
    }
   ],
   "source": [
    "print(len(Quote),len(Author),len(Type_of_Quote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "87ea952c-bbd6-4e98-b2de-252da107d5f9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type of Quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Regret for the things we did can be tempered b...</td>\n",
       "      <td>Sydney J. Harris</td>\n",
       "      <td>Love, Inspirational, Motivational</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>America... just a nation of two hundred millio...</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Gun, Two, Qualms About</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>For every disciplined effort there is a multip...</td>\n",
       "      <td>Jim Rohn</td>\n",
       "      <td>Inspirational, Greatness, Best Effort</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>The spiritual journey is individual, highly pe...</td>\n",
       "      <td>Ram Dass</td>\n",
       "      <td>Spiritual, Truth, Yoga</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>The mind is not a vessel to be filled but a fi...</td>\n",
       "      <td>Plutarch</td>\n",
       "      <td>Inspirational, Leadership, Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote              Author  \\\n",
       "0    The essence of strategy is choosing what not t...      Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...          Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...  Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...      Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...        Erma Bombeck   \n",
       "..                                                 ...                 ...   \n",
       "995  Regret for the things we did can be tempered b...    Sydney J. Harris   \n",
       "996  America... just a nation of two hundred millio...  Hunter S. Thompson   \n",
       "997  For every disciplined effort there is a multip...            Jim Rohn   \n",
       "998  The spiritual journey is individual, highly pe...            Ram Dass   \n",
       "999  The mind is not a vessel to be filled but a fi...            Plutarch   \n",
       "\n",
       "                                Type of Quote  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995         Love, Inspirational, Motivational  \n",
       "996                    Gun, Two, Qualms About  \n",
       "997     Inspirational, Greatness, Best Effort  \n",
       "998                    Spiritual, Truth, Yoga  \n",
       "999      Inspirational, Leadership, Education  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4 : Creating Data Frame\n",
    "df8 = pd.DataFrame({'Quote':Quote,'Author':Author,'Type of Quote':Type_of_Quote})\n",
    "df8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd064772-a23c-41dc-95b5-3666e8c02804",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d3245f6-3619-43f8-ae6b-9a5dca08b10a",
   "metadata": {},
   "source": [
    "### Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9711f263-ad91-4098-a74c-9e5ffe3515ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b5f80198-bffa-4c30-bb62-ac32c838b9d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1 : getting the webpage https://www.jagranjosh.com/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# going to naukari.com\n",
    "driver.get('https://www.jagranjosh.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "d410718d-508d-46cd-b102-4a3d645bfea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Clicking on GK Option\n",
    "gk_op_btn = driver.find_element(By.XPATH,'/html/body/div/div[1]/div/div[1]/div/div[5]/div/div[1]/header/div[3]/ul/li[3]/a')\n",
    "gk_op_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fc96b100-934f-4177-bb4d-74c39274d830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: Clicking on List of all Prime Ministers of India\n",
    "pm_list = driver.find_element(By.XPATH,'/html/body/div[1]/div/div/div[2]/div/div[10]/div/div/ul/li[2]/a')\n",
    "pm_list.location_once_scrolled_into_view\n",
    "pm_list.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7af24204-74ae-429c-950c-32168c0914f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4 : Scraping web data\n",
    "#creating empty lists\n",
    "Name = []\n",
    "Born_Dead = []\n",
    "Term_of_office= []\n",
    "Term_of_office_days= []\n",
    "Remarks = []\n",
    "# web scraping\n",
    "data = driver.find_element(By.XPATH,'//div[@class=\"table-box\"]')\n",
    "# scraping Born Dead data\n",
    "for i in range(7,len(data.text.split('\\n')),6):\n",
    "    Born_Dead.append(data.text.split('\\n')[i][1:-1])\n",
    "\n",
    "# scraping Name data \n",
    "for i in range(6,len(data.text.split('\\n')),6):\n",
    "    Name.append(data.text.split('\\n')[i])\n",
    "\n",
    "# scraping Term of office data\n",
    "for i in range(8,len(data.text.split('\\n')),6):\n",
    "    Term_of_office.append(data.text.split('\\n')[i])    \n",
    "\n",
    "# scraping Term of office in days data\n",
    "for i in range(9,len(data.text.split('\\n'))-1,6):\n",
    "    Term_of_office_days.append(data.text.split('\\n')[i])\n",
    "# Adding Narendra Modi data    \n",
    "Term_of_office_days.append('Ongoing')    \n",
    "\n",
    "# scraping Remarks data\n",
    "for i in range(10,len(data.text.split('\\n')),6):\n",
    "    Remarks.append(data.text.split('\\n')[i])\n",
    "# Adding Narendra Modi data\n",
    "Remarks.append(data.text.split('\\n')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6bdf4af1-f383-4d8e-8bab-c54db7b0450e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 18 18 18 18\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Born_Dead),len(Term_of_office),len(Term_of_office_days),len(Remarks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "14b96a1e-47e1-4205-88ef-cdeb6b551ab7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Born Dead</th>\n",
       "      <th>Term of office</th>\n",
       "      <th>Term of office in days</th>\n",
       "      <th>Remarks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jawahar Lal Nehru</td>\n",
       "      <td>1889–1964</td>\n",
       "      <td>15 August 1947 to 27 May 1964</td>\n",
       "      <td>16 years, 286 days</td>\n",
       "      <td>The first prime minister of India and the long...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gulzarilal Nanda (Acting)</td>\n",
       "      <td>1898-1998</td>\n",
       "      <td>27 May 1964 to 9 June 1964,</td>\n",
       "      <td>13 days</td>\n",
       "      <td>First acting PM of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lal Bahadur Shastri</td>\n",
       "      <td>1904–1966</td>\n",
       "      <td>9 June 1964 to 11 January 1966</td>\n",
       "      <td>1 year, 216 days</td>\n",
       "      <td>He has given the slogan of 'Jai Jawan Jai Kisa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gulzari Lal Nanda  (Acting)</td>\n",
       "      <td>1898-1998</td>\n",
       "      <td>11 January 1966 to 24 January 1966</td>\n",
       "      <td>13 days</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>1917–1984</td>\n",
       "      <td>24 January 1966 to 24 March 1977</td>\n",
       "      <td>11 years, 59 days</td>\n",
       "      <td>First female Prime Minister of India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Morarji Desai</td>\n",
       "      <td>1896–1995</td>\n",
       "      <td>24 March 1977 to  28 July 1979</td>\n",
       "      <td>2 year, 126 days</td>\n",
       "      <td>Oldest to become PM (81 years old) and first t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Charan Singh</td>\n",
       "      <td>1902–1987</td>\n",
       "      <td>28 July 1979 to 14 January 1980</td>\n",
       "      <td>170 days</td>\n",
       "      <td>Only PM who did not face the Parliament</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Indira Gandhi</td>\n",
       "      <td>1917–1984</td>\n",
       "      <td>14 January 1980 to 31 October 1984</td>\n",
       "      <td>4 years, 291 days</td>\n",
       "      <td>The first lady who served as PM for the second...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rajiv Gandhi</td>\n",
       "      <td>1944–1991</td>\n",
       "      <td>31 October 1984 to 2 December 1989</td>\n",
       "      <td>5 years, 32 days</td>\n",
       "      <td>Youngest to become PM (40 years old)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>V. P. Singh</td>\n",
       "      <td>1931–2008</td>\n",
       "      <td>2 December 1989 to 10 November 1990</td>\n",
       "      <td>343 days</td>\n",
       "      <td>First PM to step down after a vote of no confi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Chandra Shekhar</td>\n",
       "      <td>1927–2007</td>\n",
       "      <td>10 November 1990 to 21 June 1991</td>\n",
       "      <td>223 days</td>\n",
       "      <td>He belongs to  Samajwadi Janata Party</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>P. V. Narasimha Rao</td>\n",
       "      <td>1921–2004</td>\n",
       "      <td>21 June 1991 to 16 May 1996</td>\n",
       "      <td>4 years, 330 days</td>\n",
       "      <td>First PM from south India</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>1924- 2018</td>\n",
       "      <td>16 May 1996 to 1 June 1996</td>\n",
       "      <td>16 days</td>\n",
       "      <td>PM for shortest tenure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>H. D. Deve Gowda</td>\n",
       "      <td>born 1933</td>\n",
       "      <td>1 June 1996 to 21 April 1997</td>\n",
       "      <td>324 days</td>\n",
       "      <td>He belongs to  Janata Dal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Inder Kumar Gujral</td>\n",
       "      <td>1919–2012</td>\n",
       "      <td>21 April 1997 to 19 March 1998</td>\n",
       "      <td>332 days</td>\n",
       "      <td>------</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Atal Bihari Vajpayee</td>\n",
       "      <td>1924-2018</td>\n",
       "      <td>19 March 1998 to 22 May 2004</td>\n",
       "      <td>6 years, 64 days</td>\n",
       "      <td>The first non-congress PM who completed a ful...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Manmohan Singh</td>\n",
       "      <td>born 1932</td>\n",
       "      <td>22 May 2004 to 26 May 2014</td>\n",
       "      <td>10 years, 4 days</td>\n",
       "      <td>First Sikh PM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Narendra Modi</td>\n",
       "      <td>born 1950</td>\n",
       "      <td>26 May 2014 - Present</td>\n",
       "      <td>Ongoing</td>\n",
       "      <td>4th Prime Minister of India who served two con...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name   Born Dead  \\\n",
       "0             Jawahar Lal Nehru   1889–1964   \n",
       "1     Gulzarilal Nanda (Acting)   1898-1998   \n",
       "2           Lal Bahadur Shastri   1904–1966   \n",
       "3   Gulzari Lal Nanda  (Acting)   1898-1998   \n",
       "4                 Indira Gandhi   1917–1984   \n",
       "5                 Morarji Desai   1896–1995   \n",
       "6                  Charan Singh   1902–1987   \n",
       "7                 Indira Gandhi   1917–1984   \n",
       "8                  Rajiv Gandhi   1944–1991   \n",
       "9                   V. P. Singh   1931–2008   \n",
       "10              Chandra Shekhar   1927–2007   \n",
       "11          P. V. Narasimha Rao   1921–2004   \n",
       "12         Atal Bihari Vajpayee  1924- 2018   \n",
       "13             H. D. Deve Gowda   born 1933   \n",
       "14           Inder Kumar Gujral   1919–2012   \n",
       "15         Atal Bihari Vajpayee   1924-2018   \n",
       "16               Manmohan Singh   born 1932   \n",
       "17                Narendra Modi   born 1950   \n",
       "\n",
       "                         Term of office Term of office in days  \\\n",
       "0         15 August 1947 to 27 May 1964     16 years, 286 days   \n",
       "1           27 May 1964 to 9 June 1964,                13 days   \n",
       "2        9 June 1964 to 11 January 1966       1 year, 216 days   \n",
       "3    11 January 1966 to 24 January 1966                13 days   \n",
       "4      24 January 1966 to 24 March 1977      11 years, 59 days   \n",
       "5       24 March 1977 to  28 July 1979        2 year, 126 days   \n",
       "6       28 July 1979 to 14 January 1980               170 days   \n",
       "7    14 January 1980 to 31 October 1984      4 years, 291 days   \n",
       "8    31 October 1984 to 2 December 1989       5 years, 32 days   \n",
       "9   2 December 1989 to 10 November 1990               343 days   \n",
       "10     10 November 1990 to 21 June 1991               223 days   \n",
       "11          21 June 1991 to 16 May 1996      4 years, 330 days   \n",
       "12           16 May 1996 to 1 June 1996                16 days   \n",
       "13         1 June 1996 to 21 April 1997               324 days   \n",
       "14      21 April 1997 to 19 March 1998                332 days   \n",
       "15        19 March 1998 to 22 May 2004        6 years, 64 days   \n",
       "16        22 May 2004 to 26 May 2014          10 years, 4 days   \n",
       "17                26 May 2014 - Present                Ongoing   \n",
       "\n",
       "                                              Remarks  \n",
       "0   The first prime minister of India and the long...  \n",
       "1                            First acting PM of India  \n",
       "2   He has given the slogan of 'Jai Jawan Jai Kisa...  \n",
       "3                                                   -  \n",
       "4                First female Prime Minister of India  \n",
       "5   Oldest to become PM (81 years old) and first t...  \n",
       "6             Only PM who did not face the Parliament  \n",
       "7   The first lady who served as PM for the second...  \n",
       "8                Youngest to become PM (40 years old)  \n",
       "9   First PM to step down after a vote of no confi...  \n",
       "10              He belongs to  Samajwadi Janata Party  \n",
       "11                          First PM from south India  \n",
       "12                             PM for shortest tenure  \n",
       "13                          He belongs to  Janata Dal  \n",
       "14                                             ------  \n",
       "15   The first non-congress PM who completed a ful...  \n",
       "16                                      First Sikh PM  \n",
       "17  4th Prime Minister of India who served two con...  "
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Creating Data Frame\n",
    "df9 = pd.DataFrame({'Name':Name,'Born Dead':Born_Dead,'Term of office':Term_of_office,'Term of office in days':Term_of_office_days,'Remarks':Remarks})\n",
    "\n",
    "df9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277de689-79b2-4378-add5-7b491839cb91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "64be6908-b426-4f40-81e0-925d2ceea7a7",
   "metadata": {},
   "source": [
    "### Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/\n",
    "#### This task will be done in following steps:\n",
    "1. First get the webpagehttps://www.motor1.com/\n",
    "2. Then You have to click on the List option from Dropdown menu on leftside.\n",
    "3. Then click on 50 most expensive cars in the world.\n",
    "4. Then scrap the mentioned data and make the dataframe.\n",
    "\n",
    "### Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ce0c8bba-4131-4b66-a383-fdf6cef6d886",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Importing all necessary libraries\n",
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0daa390d-8547-4fdf-b1c1-ba4dc872e090",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1 : getting the webpage https://www.motor1.com/\n",
    "# connecting to chrome driver\n",
    "driver = webdriver.Chrome(r\"C:\\Users\\kiran\\Desktop\\datatrained\\jupitor notebooks\\Internship\\webdriver\\chromedriver.exe\")\n",
    "# going to naukari.com\n",
    "driver.get('https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ceaa108b-ccce-4417-af8e-515c08105bc5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 2 : Clicking on the List option from Dropdown menu on leftside.\n",
    "\n",
    "#clicling options button\n",
    "opt_btn= driver.find_element(By.XPATH,'//div[@class=\"m1-hamburger-button\"]')\n",
    "opt_btn.click()\n",
    "# waiting for page to load\n",
    "time.sleep(2)\n",
    "\n",
    "# clicling drop down button\n",
    "dropdown_btn= driver.find_element(By.XPATH,'/html/body/div[4]/div[1]/div[3]/ul/li[5]/button')\n",
    "dropdown_btn.click()\n",
    "time.sleep(0.25)\n",
    "\n",
    "# clicling list option\n",
    "list_btn= driver.find_element(By.XPATH,'/html/body/div[4]/div[1]/div[3]/ul/li[6]/ul/li[1]/a')\n",
    "list_btn.click()\n",
    "time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "097b201a-c916-4ba8-9cea-9b2bb6f59ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3 : clicking on 50 most expensive cars in the world.\n",
    "exp_cars_btn = driver.find_element(By.XPATH,'/html/body/div[3]/div[8]/div[1]/div[1]/div/div/div[7]/div/div[1]')\n",
    "exp_cars_btn.click()\n",
    "time.sleep(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4b60e792-1eab-491c-8f8e-3dce450c0030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 4 : Scraping Required Data\n",
    "\n",
    "# Creating Empty List\n",
    "Car_name=[]\n",
    "Price = []\n",
    "\n",
    "#Scraping Name data\n",
    "Car_name_data= driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]')\n",
    "for i in range(50):    \n",
    "    Car_name.append(Car_name_data[i].text)\n",
    "    \n",
    "#scraping Price Data\n",
    "Price_data= driver.find_elements(By.XPATH,'//strong')\n",
    "#scraping based on text\n",
    "for i in Price_data:\n",
    "    if i.text == \"\":\n",
    "        pass\n",
    "    elif i.text[:6] == 'Price:':\n",
    "        Price.append(i.text[7:])\n",
    "    elif i.text[0] == '$':\n",
    "        Price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "90169fe9-70ed-4d08-acbf-6f4f130930e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 50\n"
     ]
    }
   ],
   "source": [
    "print(len(Car_name),len(Price))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "7338eaa9-80d3-4157-8e66-5ccb7011c063",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Car Name</th>\n",
       "      <th>Car Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>De Tomaso P72</td>\n",
       "      <td>$1.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ferrari LaFerrari</td>\n",
       "      <td>$1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pagani Huayra</td>\n",
       "      <td>$1.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>McLaren Elva</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Czinger 21C</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ferrari Monza</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Gordon Murray T.33</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Koenigsegg Gemera</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Zenvo TSR-S</td>\n",
       "      <td>$1.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hennessey Venom F5</td>\n",
       "      <td>$1.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Bentley Bacalar</td>\n",
       "      <td>$1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Hispano Suiza Carmen Boulogne</td>\n",
       "      <td>$1.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Bentley Mulliner Batur</td>\n",
       "      <td>$2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Deus Vayanne</td>\n",
       "      <td>$2.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SSC Tuatara</td>\n",
       "      <td>$2.0 Million*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Lotus Evija</td>\n",
       "      <td>$2.1 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Aston Martin Vulcan</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Delage D12</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>McLaren Speedtail</td>\n",
       "      <td>$2.3 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rimac Nevera</td>\n",
       "      <td>$2.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pagani Utopia</td>\n",
       "      <td>$2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pininfarina Battista</td>\n",
       "      <td>$2.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ferrari FXX K Evo</td>\n",
       "      <td>$2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Gordon Murray T.50</td>\n",
       "      <td>$2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Lamborghini Countach</td>\n",
       "      <td>$2.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Mercedes-AMG Project One</td>\n",
       "      <td>$2.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Aston Martin Victor</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Hennessey Venom F5 Roadster</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Koenigsegg Jesko</td>\n",
       "      <td>$3.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Aston Martin Valkyrie</td>\n",
       "      <td>$3.2 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>W Motors Lykan Hypersport</td>\n",
       "      <td>$3.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>McLaren Solus</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Pagani Huayra Roadster BC</td>\n",
       "      <td>$3.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Bugatti Chiron Pur Sport</td>\n",
       "      <td>$3.6 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Lamborghini Sian</td>\n",
       "      <td>$3.6 million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Koenigsegg CC850</td>\n",
       "      <td>$3.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Bugatti Chiron Super Sport 300+</td>\n",
       "      <td>$3.9 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Lamborghini Veneno</td>\n",
       "      <td>$4.5 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Bugatti Bolide</td>\n",
       "      <td>$4.7 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Bugatti Mistral</td>\n",
       "      <td>$5.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Pagani Huayra Imola</td>\n",
       "      <td>$5.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Bugatti Divo</td>\n",
       "      <td>$5.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SP Automotive Chaos</td>\n",
       "      <td>$6.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Pagani Codalunga</td>\n",
       "      <td>$7.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Mercedes-Maybach Exelero</td>\n",
       "      <td>$8.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Bugatti Centodieci</td>\n",
       "      <td>$9.0 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Bugatti Chiron Profilée</td>\n",
       "      <td>$10.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Rolls-Royce Sweptail</td>\n",
       "      <td>$12.8 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Bugatti La Voiture Noire</td>\n",
       "      <td>$13.4 Million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Rolls-Royce Boat Tail*</td>\n",
       "      <td>$28.0 Million (est.)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Car Name             Car Price\n",
       "0                     De Tomaso P72          $1.3 Million\n",
       "1                 Ferrari LaFerrari          $1.4 Million\n",
       "2                     Pagani Huayra          $1.4 Million\n",
       "3                      McLaren Elva          $1.7 Million\n",
       "4                       Czinger 21C          $1.7 Million\n",
       "5                     Ferrari Monza          $1.7 Million\n",
       "6                Gordon Murray T.33          $1.7 Million\n",
       "7                 Koenigsegg Gemera          $1.7 Million\n",
       "8                       Zenvo TSR-S          $1.7 Million\n",
       "9                Hennessey Venom F5          $1.8 Million\n",
       "10                  Bentley Bacalar          $1.9 Million\n",
       "11    Hispano Suiza Carmen Boulogne          $1.9 Million\n",
       "12           Bentley Mulliner Batur          $2.0 Million\n",
       "13                     Deus Vayanne          $2.0 Million\n",
       "14                      SSC Tuatara         $2.0 Million*\n",
       "15                      Lotus Evija          $2.1 Million\n",
       "16              Aston Martin Vulcan          $2.3 Million\n",
       "17                       Delage D12          $2.3 Million\n",
       "18                McLaren Speedtail          $2.3 Million\n",
       "19                     Rimac Nevera          $2.4 Million\n",
       "20                    Pagani Utopia          $2.5 Million\n",
       "21             Pininfarina Battista          $2.5 Million\n",
       "22                Ferrari FXX K Evo          $2.6 Million\n",
       "23               Gordon Murray T.50          $2.6 Million\n",
       "24             Lamborghini Countach          $2.6 Million\n",
       "25         Mercedes-AMG Project One          $2.7 Million\n",
       "26              Aston Martin Victor          $3.0 Million\n",
       "27      Hennessey Venom F5 Roadster          $3.0 Million\n",
       "28                 Koenigsegg Jesko          $3.0 Million\n",
       "29            Aston Martin Valkyrie          $3.2 Million\n",
       "30        W Motors Lykan Hypersport          $3.4 Million\n",
       "31                    McLaren Solus          $3.5 Million\n",
       "32        Pagani Huayra Roadster BC          $3.5 Million\n",
       "33         Bugatti Chiron Pur Sport          $3.6 Million\n",
       "34                 Lamborghini Sian          $3.6 million\n",
       "35                 Koenigsegg CC850          $3.7 Million\n",
       "36  Bugatti Chiron Super Sport 300+          $3.9 Million\n",
       "37               Lamborghini Veneno          $4.5 Million\n",
       "38                   Bugatti Bolide          $4.7 Million\n",
       "39                  Bugatti Mistral          $5.0 Million\n",
       "40              Pagani Huayra Imola          $5.4 Million\n",
       "41                     Bugatti Divo          $5.8 Million\n",
       "42              SP Automotive Chaos          $6.4 Million\n",
       "43                 Pagani Codalunga          $7.4 Million\n",
       "44         Mercedes-Maybach Exelero          $8.0 Million\n",
       "45               Bugatti Centodieci          $9.0 Million\n",
       "46          Bugatti Chiron Profilée         $10.8 Million\n",
       "47             Rolls-Royce Sweptail         $12.8 Million\n",
       "48         Bugatti La Voiture Noire         $13.4 Million\n",
       "49           Rolls-Royce Boat Tail*  $28.0 Million (est.)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5: Creating Data Frame\n",
    "df10 = pd.DataFrame({'Car Name':Car_name,'Car Price':Price})\n",
    "\n",
    "df10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43147956-7b7f-4f05-a96b-ee6443153a88",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
